{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/tmdwh/Desktop/SEUNGJO/dacon/competition_data/train.csv')\n",
    "test = pd.read_csv('C:/Users/tmdwh/Desktop/SEUNGJO/dacon/competition_data/test.csv')\n",
    "submission = pd.read_csv('C:/Users/tmdwh/Desktop/SEUNGJO/dacon/competition_data/submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 70 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         15000 non-null  int64  \n",
      " 1   Q1            14959 non-null  float64\n",
      " 2   Q2            14931 non-null  float64\n",
      " 3   Q3            14950 non-null  float64\n",
      " 4   Q4            14929 non-null  float64\n",
      " 5   Q5            14962 non-null  float64\n",
      " 6   Q6            14952 non-null  float64\n",
      " 7   Q7            14924 non-null  float64\n",
      " 8   Q8            14952 non-null  float64\n",
      " 9   Q9            14944 non-null  float64\n",
      " 10  Q10           14928 non-null  float64\n",
      " 11  Q11           14941 non-null  float64\n",
      " 12  Q12           14933 non-null  float64\n",
      " 13  Q13           14960 non-null  float64\n",
      " 14  Q14           14964 non-null  float64\n",
      " 15  Q15           14955 non-null  float64\n",
      " 16  Q16           14967 non-null  float64\n",
      " 17  Q17           14963 non-null  float64\n",
      " 18  Q18           14937 non-null  float64\n",
      " 19  Q19           14947 non-null  float64\n",
      " 20  Q20           14955 non-null  float64\n",
      " 21  Q21           14961 non-null  float64\n",
      " 22  Q22           14962 non-null  float64\n",
      " 23  Q23           14950 non-null  float64\n",
      " 24  Q24           14939 non-null  float64\n",
      " 25  Q25           14956 non-null  float64\n",
      " 26  Q26           14932 non-null  float64\n",
      " 27  country       14810 non-null  object \n",
      " 28  introelapse   15000 non-null  int64  \n",
      " 29  testelapse    15000 non-null  int64  \n",
      " 30  surveyelapse  15000 non-null  int64  \n",
      " 31  TIPI1         14947 non-null  float64\n",
      " 32  TIPI2         14934 non-null  float64\n",
      " 33  TIPI3         14921 non-null  float64\n",
      " 34  TIPI4         14936 non-null  float64\n",
      " 35  TIPI5         14930 non-null  float64\n",
      " 36  TIPI6         14938 non-null  float64\n",
      " 37  TIPI7         14936 non-null  float64\n",
      " 38  TIPI8         14935 non-null  float64\n",
      " 39  TIPI9         14936 non-null  float64\n",
      " 40  TIPI10        14920 non-null  float64\n",
      " 41  VCL1          15000 non-null  int64  \n",
      " 42  VCL2          15000 non-null  int64  \n",
      " 43  VCL3          15000 non-null  int64  \n",
      " 44  VCL4          15000 non-null  int64  \n",
      " 45  VCL5          15000 non-null  int64  \n",
      " 46  VCL6          15000 non-null  int64  \n",
      " 47  VCL7          15000 non-null  int64  \n",
      " 48  VCL8          15000 non-null  int64  \n",
      " 49  VCL9          15000 non-null  int64  \n",
      " 50  VCL10         15000 non-null  int64  \n",
      " 51  VCL11         15000 non-null  int64  \n",
      " 52  VCL12         15000 non-null  int64  \n",
      " 53  VCL13         15000 non-null  int64  \n",
      " 54  VCL14         15000 non-null  int64  \n",
      " 55  VCL15         15000 non-null  int64  \n",
      " 56  VCL16         15000 non-null  int64  \n",
      " 57  education     14833 non-null  float64\n",
      " 58  urban         15000 non-null  int64  \n",
      " 59  gender        14981 non-null  float64\n",
      " 60  engnat        14953 non-null  float64\n",
      " 61  age           15000 non-null  int64  \n",
      " 62  hand          14953 non-null  float64\n",
      " 63  religion      14755 non-null  float64\n",
      " 64  orientation   14601 non-null  float64\n",
      " 65  voted         14915 non-null  float64\n",
      " 66  married       14918 non-null  float64\n",
      " 67  familysize    14681 non-null  float64\n",
      " 68  ASD           14911 non-null  float64\n",
      " 69  nerdiness     15000 non-null  int64  \n",
      "dtypes: float64(46), int64(23), object(1)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan값 전부 0으로 삽입\n",
    "train.fillna(0, inplace= True)\n",
    "test.fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관관계가 적은 시간 특성, 인덱스 col을 제거\n",
    "\n",
    "drop_list = ['introelapse', 'testelapse', 'surveyelapse', 'index',]\n",
    "\n",
    "train.drop(drop_list, axis = 1, inplace = True)\n",
    "test.drop(drop_list, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncategorical_columns = ['gender', 'married', 'education', 'voted', 'urban', 'orientation', 'religion', 'engnat']\\n\\nfor category in categorical_columns:\\n    train.loc[train[category] == 0, category] = train[category].mean()\\n    test.loc[test[category] == 0, category] = test[category].mean()\\n    \""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0값을 해당 특성의 train의 평균값으로 처리\n",
    "processing_feature = ['gender', 'married', 'education', 'voted', 'urban', 'orientation', 'religion', 'engnat', 'ASD']\n",
    "\n",
    "for pro in processing_feature:\n",
    "    train.loc[train[pro] == 0, pro] = train[pro].mean()\n",
    "    test.loc[test[pro] == 0, pro] = train[pro].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age 이상치(80살 이상) 0으로 처리\n",
    "train.loc[train['age'] > 80, 'age'] = 0\n",
    "test.loc[test['age'] > 80, 'age'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age의 이상치는 train데이터의 평균값으로 처리\n",
    "train.loc[train['age'] == 0, 'age'] = train['age'].mean()\n",
    "test.loc[test['age'] == 0, 'age'] = train['age'].mean()\n",
    "\n",
    "#familysize 6 이상인 값 최빈값으로 교체, \n",
    "train.loc[train['familysize'] > 6, 'familysize'] = train['familysize'].mode()[0]\n",
    "test.loc[test['familysize'] > 6, 'familysize'] = train['familysize'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터에 존재하는 상위 6개의 나라\n",
    "top6_country = train['country'].value_counts().keys()[:6]\n",
    "\n",
    "# train데이터 상위 6개 국가 제외 train데이터의 최빈값으로 처리\n",
    "for i in range(len(train['country'])):\n",
    "    if train['country'][i] not in top6_country or train['country'][i]==0:\n",
    "        train['country'][i] = train['country'].mode()[0]\n",
    "\n",
    "# test데이터 상위 6개 국가 제외 train데이터의 최빈값으로 처리\n",
    "for i in range(len(test['country'])):\n",
    "    if test['country'][i] not in top6_country or test['country'][i]==0:\n",
    "        test['country'][i] = train['country'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country 특성 원-핫인코딩 수행 (country 특성 세부 분할)\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
       "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
       "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
       "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2',\n",
       "       'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10',\n",
       "       'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education',\n",
       "       'urban', 'gender', 'engnat', 'age', 'hand', 'religion', 'orientation',\n",
       "       'voted', 'married', 'familysize', 'ASD', 'nerdiness', 'country_AUS',\n",
       "       'country_CAN', 'country_DEU', 'country_GBR', 'country_PHL',\n",
       "       'country_USA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마키아벨리즘에 대한 질문 점수\n",
    "makia_survey = ['Q' + str(i+1) for i in range(20)]\n",
    "not_makia = ['Q3', 'Q4', 'Q6','Q7', 'Q9', 'Q10', 'Q11', 'Q14', 'Q16', 'Q17', 'Q18']\n",
    "# 'Q6', 'Q14', 'Q18'\n",
    "# 'Q21', 'Q22', 'Q23', 'Q23', 'Q24', 'Q25', 'Q26'은 secret question이라 제외\n",
    "\n",
    "for columns in not_makia:\n",
    "    train.loc[train[columns] > 0, columns] = 6 - train[columns]\n",
    "    test.loc[test[columns] > 0, columns] = 6 - test[columns]\n",
    "\n",
    "\n",
    "\n",
    "# 기준치 (60점 이상)에 관련된 파생변수 생성\n",
    "train['makia_score'] = np.sum(train[makia_survey], axis = 1)\n",
    "test['makia_score'] = np.sum(test[makia_survey], axis = 1)\n",
    "\n",
    "train['high_makia'] = train['makia_score'].apply(lambda x : (1 if x > 60 else 0))\n",
    "test['high_makia'] = test['makia_score'].apply(lambda x : (1 if x > 60 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
       "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
       "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
       "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2',\n",
       "       'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10',\n",
       "       'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education',\n",
       "       'urban', 'gender', 'engnat', 'age', 'hand', 'religion', 'orientation',\n",
       "       'voted', 'married', 'familysize', 'ASD', 'nerdiness', 'country_AUS',\n",
       "       'country_CAN', 'country_DEU', 'country_GBR', 'country_PHL',\n",
       "       'country_USA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " TIPI에 대한 질문 점수\n",
    " TIPI는 1 ~ 7점까지 존재 -> 1 ~ 5점으로 변환\n",
    " TIPI 1점 -> 1점\n",
    " TIPI 2점 -> 2점\n",
    " TIPI 3점 -> 3점\n",
    " TIPI 4점 -> 3점\n",
    " TIPI 5점 -> 3점\n",
    " TIPI 6점 -> 4점 \n",
    " TIPI 7점 -> 5점\n",
    "'''\n",
    "TIPI_columns = ['TIPI' + str(x + 1) for x in range(10)]\n",
    "TIPI_score = {1:1, 2:2, 3:4, 3:5, 4:6, 5:7}\n",
    "\n",
    "\n",
    "for tipi in TIPI_columns:\n",
    "    train[tipi] = train[tipi].map(TIPI_score)\n",
    "    test[tipi] = test[tipi].map(TIPI_score)\n",
    "\n",
    "train[TIPI_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[TIPI_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPI1</th>\n",
       "      <th>TIPI2</th>\n",
       "      <th>TIPI3</th>\n",
       "      <th>TIPI4</th>\n",
       "      <th>TIPI5</th>\n",
       "      <th>TIPI6</th>\n",
       "      <th>TIPI7</th>\n",
       "      <th>TIPI8</th>\n",
       "      <th>TIPI9</th>\n",
       "      <th>TIPI10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.751267</td>\n",
       "      <td>4.563400</td>\n",
       "      <td>5.229400</td>\n",
       "      <td>4.851333</td>\n",
       "      <td>5.795333</td>\n",
       "      <td>5.463467</td>\n",
       "      <td>5.312800</td>\n",
       "      <td>4.520667</td>\n",
       "      <td>4.739667</td>\n",
       "      <td>3.012867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.054510</td>\n",
       "      <td>1.802091</td>\n",
       "      <td>1.500975</td>\n",
       "      <td>1.870044</td>\n",
       "      <td>1.140087</td>\n",
       "      <td>1.590357</td>\n",
       "      <td>1.487157</td>\n",
       "      <td>1.904297</td>\n",
       "      <td>1.760180</td>\n",
       "      <td>1.948270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TIPI1         TIPI2         TIPI3         TIPI4         TIPI5  \\\n",
       "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean       3.751267      4.563400      5.229400      4.851333      5.795333   \n",
       "std        2.054510      1.802091      1.500975      1.870044      1.140087   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        2.000000      5.000000      5.000000      5.000000      5.000000   \n",
       "50%        5.000000      5.000000      5.000000      5.000000      6.000000   \n",
       "75%        5.000000      6.000000      6.000000      6.000000      7.000000   \n",
       "max        7.000000      7.000000      7.000000      7.000000      7.000000   \n",
       "\n",
       "              TIPI6         TIPI7         TIPI8         TIPI9        TIPI10  \n",
       "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000  \n",
       "mean       5.463467      5.312800      4.520667      4.739667      3.012867  \n",
       "std        1.590357      1.487157      1.904297      1.760180      1.948270  \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000  \n",
       "25%        5.000000      5.000000      2.000000      5.000000      1.000000  \n",
       "50%        6.000000      5.000000      5.000000      5.000000      2.000000  \n",
       "75%        7.000000      6.000000      6.000000      6.000000      5.000000  \n",
       "max        7.000000      7.000000      7.000000      7.000000      7.000000  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TIPI 관련 파생변수 생성\n",
    "\n",
    "성실성 : {3번 점수 + (8 - '8번 점수')} ÷ 2\n",
    "우호성 : {7번 점수 + (8 - '2번 점수')} ÷ 2\n",
    "정서적 안정성(점수가 낮으면 신경성과 관련): {9번 점수 + (8 - '4번 점수')} ÷ 2\n",
    "개방성 : {5번 점수 + (8 - '10번 점수')} ÷ 2\n",
    "외향성 : {1번 점수 + (8 - '6번 점수')} ÷ 2\n",
    "'''\n",
    "\n",
    "train['diligence'] = (train['TIPI3'] + 8 - train['TIPI8']) / 2\n",
    "train['friendliness'] = (train['TIPI7'] + 8- train['TIPI2']) / 2\n",
    "train['stability'] = (train['TIPI9'] + 8 - train['TIPI4']) / 2\n",
    "train['openness'] = (train['TIPI5'] + 8 - train['TIPI10']) / 2\n",
    "train['extroversion'] = (train['TIPI1'] + 8 - train['TIPI6']) / 2\n",
    "\n",
    "\n",
    "test['diligence'] = (test['TIPI3'] + 8 - test['TIPI8']) / 2\n",
    "test['friendliness'] = (test['TIPI7'] + 8- test['TIPI2']) / 2\n",
    "test['stability'] = (test['TIPI9'] + 8 - test['TIPI4']) / 2\n",
    "test['openness'] = (test['TIPI5'] + 8 - test['TIPI10']) / 2\n",
    "test['extroversion'] = (test['TIPI1'] + 8 - test['TIPI6']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPI1</th>\n",
       "      <th>TIPI2</th>\n",
       "      <th>TIPI3</th>\n",
       "      <th>TIPI4</th>\n",
       "      <th>TIPI5</th>\n",
       "      <th>TIPI6</th>\n",
       "      <th>TIPI7</th>\n",
       "      <th>TIPI8</th>\n",
       "      <th>TIPI9</th>\n",
       "      <th>TIPI10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "      <td>35452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.738153</td>\n",
       "      <td>4.527897</td>\n",
       "      <td>5.200468</td>\n",
       "      <td>4.840742</td>\n",
       "      <td>5.802663</td>\n",
       "      <td>5.468070</td>\n",
       "      <td>5.316315</td>\n",
       "      <td>4.535372</td>\n",
       "      <td>4.749662</td>\n",
       "      <td>2.978816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.065309</td>\n",
       "      <td>1.817297</td>\n",
       "      <td>1.526410</td>\n",
       "      <td>1.873197</td>\n",
       "      <td>1.139026</td>\n",
       "      <td>1.575324</td>\n",
       "      <td>1.510887</td>\n",
       "      <td>1.903089</td>\n",
       "      <td>1.768045</td>\n",
       "      <td>1.945080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TIPI1         TIPI2         TIPI3         TIPI4         TIPI5  \\\n",
       "count  35452.000000  35452.000000  35452.000000  35452.000000  35452.000000   \n",
       "mean       3.738153      4.527897      5.200468      4.840742      5.802663   \n",
       "std        2.065309      1.817297      1.526410      1.873197      1.139026   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        2.000000      5.000000      5.000000      5.000000      5.000000   \n",
       "50%        5.000000      5.000000      5.000000      5.000000      6.000000   \n",
       "75%        5.000000      6.000000      6.000000      6.000000      7.000000   \n",
       "max        7.000000      7.000000      7.000000      7.000000      7.000000   \n",
       "\n",
       "              TIPI6         TIPI7         TIPI8         TIPI9        TIPI10  \n",
       "count  35452.000000  35452.000000  35452.000000  35452.000000  35452.000000  \n",
       "mean       5.468070      5.316315      4.535372      4.749662      2.978816  \n",
       "std        1.575324      1.510887      1.903089      1.768045      1.945080  \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000  \n",
       "25%        5.000000      5.000000      2.000000      5.000000      1.000000  \n",
       "50%        6.000000      5.000000      5.000000      5.000000      2.000000  \n",
       "75%        7.000000      6.000000      6.000000      6.000000      5.000000  \n",
       "max        7.000000      7.000000      7.000000      7.000000      7.000000  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA 결과 50대 이상일수록 nerdiness가 1인 비율이 많아짐. => 관련 파생변수 생성\n",
    "def age_to_category(age):\n",
    "    normalize = age // 10\n",
    "    if normalize == 1:\n",
    "        return 'children'\n",
    "    elif (normalize >= 2) & (normalize <= 3):\n",
    "        return 'adult'\n",
    "    elif (normalize >= 4) & (normalize <= 6):\n",
    "        return 'middle age'\n",
    "    else:\n",
    "        return 'old age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_category'] = train['age'].apply(lambda x : age_to_category(x))\n",
    "counts = train.groupby('age_category')['nerdiness'].value_counts(normalize = True).rename('percentage').mul(100).reset_index()\n",
    "sns.barplot(x = 'age_category', y = 'percentage', hue = 'nerdiness', data = counts)\n",
    "test['age_category'] = test['age'].apply(lambda x : age_to_category(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age 특성 원-핫인코딩 수행 (age 특성 세부 분할)\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 종교와 관련하여 nerdiness 변화가 뚜렷함.\n",
    "def convert_environment(x):\n",
    "    if ((x == '2.0') | (x == '5.0') | (x == '9.0')):\n",
    "        return 0\n",
    "    elif ((x == '1.0') | (x == '12.0') | (x == '6.0') | (x == '7.0')):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "train['religion_environment'] = train['religion'].apply(lambda x : convert_environment(x))\n",
    "test['religion_environment'] = test['religion'].apply(lambda x : convert_environment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# age, religion -> 삭제\n",
    "train.drop(['age', 'religion'], axis = 1, inplace = True)\n",
    "test.drop(['age', 'religion'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20.0\n",
       "1        49.0\n",
       "2        43.0\n",
       "3        17.0\n",
       "4        18.0\n",
       "         ... \n",
       "14995    17.0\n",
       "14996    45.0\n",
       "14997    20.0\n",
       "14998    29.0\n",
       "14999    21.0\n",
       "Name: age, Length: 15000, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13204\\2388612359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[0;32m     31\u001b[0m \u001b[1;31m# Hyperparameter Tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     32\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSuccessiveHalvingPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 33\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    291\u001b[0m                 self._optimize_sequential(\n",
      "\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    293\u001b[0m                 )\n",
      "\u001b[0;32m    294\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n",
      "\u001b[0;32m    652\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    656\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n",
      "\u001b[0;32m    683\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    687\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n",
      "\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    708\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 709\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    711\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13204\\2388612359.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n",
      "\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_valid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_trains\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_valids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     22\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     25\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n",
      "\u001b[0;32m    970\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    971\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 972\u001b[1;33m                     callbacks=callbacks, init_model=init_model)\n",
      "\u001b[0m\u001b[0;32m    973\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n",
      "\u001b[0;32m    756\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    757\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 758\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    759\u001b[0m         )\n",
      "\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n",
      "\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n",
      "\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n",
      "\u001b[0;32m   3021\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 3023\u001b[1;33m                 ctypes.byref(is_finished)))\n",
      "\u001b[0m\u001b[0;32m   3024\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3025\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!pip install --quiet optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
       "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
       "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
       "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2',\n",
       "       'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10',\n",
       "       'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education',\n",
       "       'urban', 'gender', 'engnat', 'hand', 'orientation', 'voted', 'married',\n",
       "       'familysize', 'ASD', 'nerdiness', 'country_AUS', 'country_CAN',\n",
       "       'country_DEU', 'country_GBR', 'country_PHL', 'country_USA',\n",
       "       'makia_score', 'high_makia', 'diligence', 'friendliness', 'stability',\n",
       "       'openness', 'extroversion', 'Tactics', 'Views', 'Morality',\n",
       "       'age_category', 'religion_environment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import SuccessiveHalvingPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 위의 방식을 사용하여 연속형 변수 이상치(outlier) 처리\\nfor time_columns in time:\\n    q1 = np.percentile(train[time_columns], 25)\\n    q3 = np.percentile(test[time_columns], 75)\\n\\n    outlier_bounds = q3 + 1.5 * (q3 - q3)\\n    train.loc[train[time_columns] >= outlier_bounds, time_columns] = outlier_bounds\\n    test.loc[test[time_columns] >= outlier_bounds, time_columns] = outlier_bounds\\n\\ntrain[time].describe()\\n'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
    "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
    "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
    "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2',\n",
    "       'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10',\n",
    "       'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education',\n",
    "       'urban', 'gender', 'engnat', 'hand', 'orientation', 'voted', 'married',\n",
    "       'familysize', 'ASD', 'country_AUS', 'country_CAN',\n",
    "       'country_DEU', 'country_GBR', 'country_PHL', 'country_USA',\n",
    "       'makia_score', 'high_makia', 'diligence', 'friendliness', 'stability',\n",
    "       'openness', 'extroversion', 'age_category_adult',\n",
    "       'age_category_children', 'age_category_middle age',\n",
    "       'age_category_old age', 'religion_environment']\n",
    "\n",
    "target = ['nerdiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# train data에 존재하는 상위 6개 나라\\nbest_country = train['country'].value_counts().keys()[:6]\\n\\n# best country가 아닌 국가는 최빈값으로 처리\\nfor i in range(len(train['country'])):\\n    if train['country'][i] not in best_country or train['country'][i] == 0:\\n        train['country'][i] = train['country'].mode()[0]\\n        \\n# test data도 동일하게 처리\\nfor i in range(len(test['country'])):\\n    if test['country'][i] not in best_country or test['country'][i] == 0:\\n        test['country'][i] = train['country'].mode()[0]\\n\""
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trains = []\n",
    "df_valids = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=2022, shuffle=True)\n",
    "for train_index, valid_index in skf.split(train[features], train[target]):\n",
    "    df_train = train.loc[train_index]\n",
    "    df_valid = train.loc[valid_index]\n",
    "    df_trains.append(df_train)\n",
    "    df_valids.append(df_valid)\n",
    "\n",
    "    x_train = df_train[features]\n",
    "    y_train = df_train[target]\n",
    "\n",
    "    x_test = df_valid[features]\n",
    "    y_test = df_valid[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
       "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
       "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
       "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2',\n",
       "       'VCL3', 'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10',\n",
       "       'VCL11', 'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education',\n",
       "       'urban', 'gender', 'engnat', 'hand', 'orientation', 'voted', 'married',\n",
       "       'familysize', 'ASD', 'nerdiness', 'country_AUS', 'country_CAN',\n",
       "       'country_DEU', 'country_GBR', 'country_PHL', 'country_USA',\n",
       "       'makia_score', 'high_makia', 'diligence', 'friendliness', 'stability',\n",
       "       'openness', 'extroversion', 'Tactics', 'Views', 'Morality',\n",
       "       'age_category', 'religion_environment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(true, pred):\n",
    "    return np.mean(true==pred)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 300, 824, step=1, log=True), \n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20, step=1, log=False), \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1, log=True), \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1500, 3000, step=1, log=True), \n",
    "        \"metric\": \"multi_auc\",\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=1, log=False), \n",
    "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0), \n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 1.0),\n",
    "        'random_state': 2022\n",
    "    }\n",
    "    \n",
    "    score = []\n",
    "    for df_train, df_valid in zip(df_trains, df_valids):\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "        pred = clf.predict_proba(df_valid[features])[:, 1]\n",
    "        true = df_valid[target].values\n",
    "        score.append(roc_auc_score(true, pred))\n",
    "    score = np.mean(score)\n",
    "    return score\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=2022), pruner=SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 54)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
       "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
       "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
       "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'education',\n",
       "       'urban', 'gender', 'engnat', 'hand', 'orientation', 'voted', 'married',\n",
       "       'familysize', 'ASD', 'nerdiness', 'country_AUS', 'country_CAN',\n",
       "       'country_DEU', 'country_GBR', 'country_PHL', 'country_USA',\n",
       "       'makia_score', 'high_makia', 'diligence', 'friendliness', 'stability',\n",
       "       'openness', 'extroversion', 'Tactics', 'Views', 'Morality',\n",
       "       'age_category', 'religion_environment', '지능', 'fake'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼파라미터 중요도\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 67 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Q1                    15000 non-null  float32\n",
      " 1   Q2                    15000 non-null  float32\n",
      " 2   Q3                    15000 non-null  float32\n",
      " 3   Q4                    15000 non-null  float32\n",
      " 4   Q5                    15000 non-null  float32\n",
      " 5   Q6                    15000 non-null  float32\n",
      " 6   Q7                    15000 non-null  float32\n",
      " 7   Q8                    15000 non-null  float32\n",
      " 8   Q9                    15000 non-null  float32\n",
      " 9   Q10                   15000 non-null  float32\n",
      " 10  Q11                   15000 non-null  float32\n",
      " 11  Q12                   15000 non-null  float32\n",
      " 12  Q13                   15000 non-null  float32\n",
      " 13  Q14                   15000 non-null  float32\n",
      " 14  Q15                   15000 non-null  float32\n",
      " 15  Q16                   15000 non-null  float32\n",
      " 16  Q17                   15000 non-null  float32\n",
      " 17  Q18                   15000 non-null  float32\n",
      " 18  Q19                   15000 non-null  float32\n",
      " 19  Q20                   15000 non-null  float32\n",
      " 20  Q21                   15000 non-null  float32\n",
      " 21  Q22                   15000 non-null  float32\n",
      " 22  Q23                   15000 non-null  float32\n",
      " 23  Q24                   15000 non-null  float32\n",
      " 24  Q25                   15000 non-null  float32\n",
      " 25  Q26                   15000 non-null  float32\n",
      " 26  TIPI1                 15000 non-null  int64  \n",
      " 27  TIPI2                 15000 non-null  int64  \n",
      " 28  TIPI3                 15000 non-null  int64  \n",
      " 29  TIPI4                 15000 non-null  int64  \n",
      " 30  TIPI5                 15000 non-null  int64  \n",
      " 31  TIPI6                 15000 non-null  int64  \n",
      " 32  TIPI7                 15000 non-null  int64  \n",
      " 33  TIPI8                 15000 non-null  int64  \n",
      " 34  TIPI9                 15000 non-null  int64  \n",
      " 35  TIPI10                15000 non-null  int64  \n",
      " 36  education             15000 non-null  object \n",
      " 37  urban                 15000 non-null  object \n",
      " 38  gender                15000 non-null  object \n",
      " 39  engnat                15000 non-null  object \n",
      " 40  hand                  15000 non-null  object \n",
      " 41  orientation           15000 non-null  object \n",
      " 42  voted                 15000 non-null  object \n",
      " 43  married               15000 non-null  object \n",
      " 44  familysize            15000 non-null  float32\n",
      " 45  ASD                   15000 non-null  object \n",
      " 46  nerdiness             15000 non-null  object \n",
      " 47  country_AUS           15000 non-null  uint8  \n",
      " 48  country_CAN           15000 non-null  uint8  \n",
      " 49  country_DEU           15000 non-null  uint8  \n",
      " 50  country_GBR           15000 non-null  uint8  \n",
      " 51  country_PHL           15000 non-null  uint8  \n",
      " 52  country_USA           15000 non-null  uint8  \n",
      " 53  makia_score           15000 non-null  float32\n",
      " 54  high_makia            15000 non-null  object \n",
      " 55  diligence             15000 non-null  float64\n",
      " 56  friendliness          15000 non-null  float64\n",
      " 57  stability             15000 non-null  float64\n",
      " 58  openness              15000 non-null  float64\n",
      " 59  extroversion          15000 non-null  float64\n",
      " 60  Tactics               15000 non-null  float32\n",
      " 61  Views                 15000 non-null  float32\n",
      " 62  Morality              15000 non-null  float32\n",
      " 63  age_category          15000 non-null  object \n",
      " 64  religion_environment  15000 non-null  object \n",
      " 65  지능                    15000 non-null  float64\n",
      " 66  fake                  15000 non-null  int64  \n",
      "dtypes: float32(31), float64(6), int64(11), object(13), uint8(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for df_train in df_trains:\n",
    "    clf = LGBMClassifier(**study.best_params)\n",
    "    clf.fit(df_train[features], df_train[target])\n",
    "    pred_clf = clf.predict_proba(x_test)[:, 1]\n",
    "    print(roc_auc_score(y_test, pred_clf))\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [clf.predict_proba(test[features]) for clf in clfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 column의 왜도 -0.9885\n",
      "Q2 column의 왜도 -1.1972\n",
      "Q3 column의 왜도 1.4591\n",
      "Q4 column의 왜도 0.7707\n",
      "Q5 column의 왜도 -0.9031\n",
      "Q6 column의 왜도 0.6339\n",
      "Q7 column의 왜도 1.3420\n",
      "Q8 column의 왜도 -0.9678\n",
      "Q9 column의 왜도 0.9139\n",
      "Q10 column의 왜도 1.1142\n",
      "Q11 column의 왜도 0.1606\n",
      "Q12 column의 왜도 -0.8517\n",
      "Q13 column의 왜도 -0.6511\n",
      "Q14 column의 왜도 0.5904\n",
      "Q15 column의 왜도 -0.0703\n",
      "Q16 column의 왜도 0.3775\n",
      "Q17 column의 왜도 0.8841\n",
      "Q18 column의 왜도 1.0026\n",
      "Q19 column의 왜도 -0.3849\n",
      "Q20 column의 왜도 -0.4999\n",
      "Q21 column의 왜도 -0.0159\n",
      "Q22 column의 왜도 0.5872\n",
      "Q23 column의 왜도 -0.9040\n",
      "Q24 column의 왜도 -1.4714\n",
      "Q25 column의 왜도 -0.1770\n",
      "Q26 column의 왜도 -1.2057\n",
      "TIPI1 column의 왜도 -0.1143\n",
      "TIPI2 column의 왜도 -0.8614\n",
      "TIPI3 column의 왜도 -1.3360\n",
      "TIPI4 column의 왜도 -0.9022\n",
      "TIPI5 column의 왜도 -1.4917\n",
      "TIPI6 column의 왜도 -1.4152\n",
      "TIPI7 column의 왜도 -1.3476\n",
      "TIPI8 column의 왜도 -0.7215\n",
      "TIPI9 column의 왜도 -0.9172\n",
      "TIPI10 column의 왜도 0.3571\n",
      "familysize column의 왜도 1.1519\n",
      "country_AUS column의 왜도 5.0609\n",
      "country_CAN column의 왜도 3.6689\n",
      "country_DEU column의 왜도 5.3620\n",
      "country_GBR column의 왜도 3.2569\n",
      "country_PHL column의 왜도 7.3824\n",
      "country_USA column의 왜도 -1.3600\n",
      "makia_score column의 왜도 0.1571\n",
      "성실성 column의 왜도 -0.0269\n",
      "우호성 column의 왜도 0.0114\n",
      "정서적 안정성 column의 왜도 0.0754\n",
      "개방성 column의 왜도 -0.4333\n",
      "외향성 column의 왜도 0.4454\n",
      "Tactics column의 왜도 -0.0037\n",
      "Views column의 왜도 -0.2227\n",
      "Morality column의 왜도 -0.0373\n",
      "지능 column의 왜도 -1.1810\n",
      "fake column의 왜도 1.9115\n"
     ]
    }
   ],
   "source": [
    "for numeric in numeric_columns:\n",
    "    print('{0} column의 왜도 {1:.4f}'.format(numeric, train[numeric].skew()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 66), (35452, 66))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[numeric_columns])\n",
    "x_scaled = pd.DataFrame(scaler.transform(train[numeric_columns]), columns = numeric_columns)\n",
    "x_test_scaled = pd.DataFrame(scaler.transform(train[numeric_columns]), columns = numeric_columns)\n",
    "\n",
    "train_data = pd.concat([train[categorical_columns], x_scaled], axis = 1)\n",
    "test_data = pd.concat([test[categorical_columns], x_test_scaled], axis = 1)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['high_makia' 'ASD'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12524\\1493135745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'high_makia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ASD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'high_makia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ASD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4913\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4914\u001b[0m         )\n\u001b[0;32m   4915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['high_makia' 'ASD'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train.drop(['high_makia', 'ASD'], axis = 1, inplace = True)\n",
    "test.drop(['high_makia', 'ASD'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 65 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Q1                    15000 non-null  float32\n",
      " 1   Q2                    15000 non-null  float32\n",
      " 2   Q3                    15000 non-null  float32\n",
      " 3   Q4                    15000 non-null  float32\n",
      " 4   Q5                    15000 non-null  float32\n",
      " 5   Q6                    15000 non-null  float32\n",
      " 6   Q7                    15000 non-null  float32\n",
      " 7   Q8                    15000 non-null  float32\n",
      " 8   Q9                    15000 non-null  float32\n",
      " 9   Q10                   15000 non-null  float32\n",
      " 10  Q11                   15000 non-null  float32\n",
      " 11  Q12                   15000 non-null  float32\n",
      " 12  Q13                   15000 non-null  float32\n",
      " 13  Q14                   15000 non-null  float32\n",
      " 14  Q15                   15000 non-null  float32\n",
      " 15  Q16                   15000 non-null  float32\n",
      " 16  Q17                   15000 non-null  float32\n",
      " 17  Q18                   15000 non-null  float32\n",
      " 18  Q19                   15000 non-null  float32\n",
      " 19  Q20                   15000 non-null  float32\n",
      " 20  Q21                   15000 non-null  float32\n",
      " 21  Q22                   15000 non-null  float32\n",
      " 22  Q23                   15000 non-null  float32\n",
      " 23  Q24                   15000 non-null  float32\n",
      " 24  Q25                   15000 non-null  float32\n",
      " 25  Q26                   15000 non-null  float32\n",
      " 26  TIPI1                 15000 non-null  int64  \n",
      " 27  TIPI2                 15000 non-null  int64  \n",
      " 28  TIPI3                 15000 non-null  int64  \n",
      " 29  TIPI4                 15000 non-null  int64  \n",
      " 30  TIPI5                 15000 non-null  int64  \n",
      " 31  TIPI6                 15000 non-null  int64  \n",
      " 32  TIPI7                 15000 non-null  int64  \n",
      " 33  TIPI8                 15000 non-null  int64  \n",
      " 34  TIPI9                 15000 non-null  int64  \n",
      " 35  TIPI10                15000 non-null  int64  \n",
      " 36  education             15000 non-null  object \n",
      " 37  urban                 15000 non-null  object \n",
      " 38  gender                15000 non-null  object \n",
      " 39  engnat                15000 non-null  object \n",
      " 40  hand                  15000 non-null  object \n",
      " 41  orientation           15000 non-null  object \n",
      " 42  voted                 15000 non-null  object \n",
      " 43  married               15000 non-null  object \n",
      " 44  familysize            15000 non-null  float32\n",
      " 45  nerdiness             15000 non-null  object \n",
      " 46  country_AUS           15000 non-null  uint8  \n",
      " 47  country_CAN           15000 non-null  uint8  \n",
      " 48  country_DEU           15000 non-null  uint8  \n",
      " 49  country_GBR           15000 non-null  uint8  \n",
      " 50  country_PHL           15000 non-null  uint8  \n",
      " 51  country_USA           15000 non-null  uint8  \n",
      " 52  makia_score           15000 non-null  float32\n",
      " 53  성실성                   15000 non-null  float64\n",
      " 54  우호성                   15000 non-null  float64\n",
      " 55  정서적 안정성               15000 non-null  float64\n",
      " 56  개방성                   15000 non-null  float64\n",
      " 57  외향성                   15000 non-null  float64\n",
      " 58  Tactics               15000 non-null  float32\n",
      " 59  Views                 15000 non-null  float32\n",
      " 60  Morality              15000 non-null  float32\n",
      " 61  age_category          15000 non-null  object \n",
      " 62  religion_environment  15000 non-null  object \n",
      " 63  지능                    15000 non-null  float64\n",
      " 64  fake                  15000 non-null  int64  \n",
      "dtypes: float32(31), float64(6), int64(11), object(11), uint8(6)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#nan 값을 전부 0으로 처리\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  ['urban', 'gender', 'engnat', 'hand', 'voted', 'married', 'age_category', 'religion_environment', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']\n",
      "one hot :  ['education', 'orientation']\n",
      "category :  ['urban', 'gender', 'engnat', 'hand', 'voted', 'married', 'age_category', 'religion_environment', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'education', 'orientation']\n",
      "numeric :  Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\n",
      "       'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21',\n",
      "       'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4',\n",
      "       'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'familysize',\n",
      "       'country_AUS', 'country_CAN', 'country_DEU', 'country_GBR',\n",
      "       'country_PHL', 'country_USA', 'makia_score', 'diligence',\n",
      "       'friendliness', 'stability', 'openness', 'extroversion', 'Tactics',\n",
      "       'Views', 'Morality', '지능', 'fake'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "label_categorical_columns = ['urban', 'gender', 'engnat', 'hand','voted', 'married', 'age_category', 'religion_environment'] + question_columns\n",
    "onehot_categorical_columns = ['education', 'orientation']\n",
    "categorical_columns = [] + label_categorical_columns + onehot_categorical_columns\n",
    "numerical_columns = [columns for columns in train.columns if columns not in ([] + label_categorical_columns + onehot_categorical_columns)]\n",
    "\n",
    "\n",
    "print('label : ', label_categorical_columns)\n",
    "print('one hot : ', onehot_categorical_columns)\n",
    "print('category : ', categorical_columns)\n",
    "print('numeric : ', numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [-2.711132155227061, -1.7983545122309461, -0.885576869234831, 0.02720077376128407, 0.9399784167573991, nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12524\\3024975182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_unknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"y contains previously unseen labels: {str(diff)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [-2.711132155227061, -1.7983545122309461, -0.885576869234831, 0.02720077376128407, 0.9399784167573991, nan]"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "label_categorical_columns = ['urban', 'gender', 'engnat', 'hand','voted', 'married', 'age_category', 'religion_environment', 'education', 'orientation'] + question_columns\n",
    "categorical_columns = [] + label_categorical_columns\n",
    "numerical_columns = [columns for columns in train.columns if columns not in ([] + label_categorical_columns)]\n",
    "\n",
    "for label in label_categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data[label])\n",
    "    train_data[label] = le.transform(train_data[label])\n",
    "    test_data[label] = le.transform(test_data[label])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서부터는 모델\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [-2.711132155227061, -1.7983545122309461, -0.885576869234831, 0.02720077376128407, 0.9399784167573991, nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12524\\1113375427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0monehot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0monehot_categorical_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tmdwh\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_unknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"y contains previously unseen labels: {str(diff)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [-2.711132155227061, -1.7983545122309461, -0.885576869234831, 0.02720077376128407, 0.9399784167573991, nan]"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "label_categorical_columns = ['urban', 'gender', 'engnat', 'hand','voted', 'married', 'age_category', 'religion_environment'] + question_columns\n",
    "onehot_categorical_columns = ['education', 'orientation']\n",
    "categorical_columns = [] + label_categorical_columns + onehot_categorical_columns\n",
    "numerical_columns = [columns for columns in train.columns if columns not in ([] + label_categorical_columns + onehot_categorical_columns)]\n",
    "\n",
    "for label in label_categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data[label])\n",
    "    train_data[label] = le.transform(train_data[label])\n",
    "    test_data[label] = le.transform(test_data[label])\n",
    "\n",
    "for onehot in onehot_categorical_columns:\n",
    "    train_data = pd.get_dummies(train_data, columns = [onehot])\n",
    "    test_data = pd.get_dummies(test_data, columns = [onehot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = train_data\n",
    "y = train['nerdiness']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size= 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def tune_model(model_type, X, Y, n_trials=100, cv=10):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    \n",
    "    if model_type=='lgb':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "            learning_rate = trial.suggest_loguniform('learning_rate', 0.05, 0.3)\n",
    "            num_leaves = trial.suggest_int('num_leaves', 7, 255)\n",
    "            reg_alpha = trial.suggest_loguniform('reg_alpha', 1e-4, 10)\n",
    "            reg_lambda = trial.suggest_loguniform('reg_lambda', 1e-4, 10)\n",
    "            colsample_bytree = trial.suggest_uniform('colsample_bytree', 0, 1)\n",
    "            subsample = trial.suggest_uniform('subsample', 0, 1)\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'learning_rate' : learning_rate, \n",
    "                      'num_leaves' : num_leaves,\n",
    "                     'reg_alpha' : reg_alpha,\n",
    "                     'reg_lambda' : reg_lambda, \n",
    "                     'colsample_bytree' : colsample_bytree, \n",
    "                     'subsample' : subsample\n",
    "                     }\n",
    "            model = lgb.LGBMClassifier(metric='auc', random_state=42, **params)\n",
    "            score = cross_val_score(model, X, Y, cv=skf, scoring='roc_auc').mean()\n",
    "            \n",
    "            return score\n",
    "    \n",
    "        \n",
    "    elif model_type=='rf':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 100)\n",
    "            max_features = trial.suggest_uniform('max_features', 0, 1)\n",
    "            criterion = trial.suggest_categorical('criterion', ['gini','entropy'])\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'max_features' : max_features, \n",
    "                      'max_depth' : max_depth,\n",
    "                      'criterion' : criterion\n",
    "                     }\n",
    "            model = RandomForestClassifier(random_state=42, **params, n_jobs=-1)\n",
    "            score = cross_val_score(model, X, Y, cv=skf, scoring='roc_auc').mean()\n",
    "            \n",
    "            return score\n",
    "        \n",
    "        \n",
    "    elif model_type=='ets':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 100)\n",
    "            max_features = trial.suggest_uniform('max_features', 0, 1)\n",
    "            criterion = trial.suggest_categorical('criterion', ['gini','entropy'])\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'max_features' : max_features, \n",
    "                      'max_depth' : max_depth,\n",
    "                      'criterion' : criterion\n",
    "                     }\n",
    "            model = ExtraTreesClassifier(random_state=42, **params, n_jobs=-1)\n",
    "            score = cross_val_score(model, X, Y, cv=skf, scoring='roc_auc').mean()\n",
    "            \n",
    "            return score\n",
    "        \n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    study=optuna.create_study(direction='maximize', \n",
    "                              sampler = sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    print(f\"Model : {model_type}, Best Score : {study.best_value}, Best Params : {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8921728717266963, 0.011232984601497732)"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier, RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "ex_params = {'n_estimators': 500, 'max_depth': 75, 'max_features': 0.20222465942018208, 'criterion': 'entropy'}\n",
    "rf_params =  {'n_estimators': 400, 'max_depth': 31, 'max_features': 0.05408093225447195, 'criterion': 'entropy'}\n",
    "lgb_params = {'n_estimators': 189, 'learning_rate': 0.06550029428021084, 'num_leaves': 249, 'reg_alpha': 0.00011906936480932443, 'reg_lambda': 0.00012169645168232884, 'colsample_bytree': 0.2231374650653746, 'subsample': 0.18089704448751198}\n",
    "\n",
    "ex_clf = ExtraTreesClassifier(**ex_params, random_state = 42)\n",
    "rf_clf = RandomForestClassifier(**rf_params, random_state = 42)\n",
    "tuned_lgbm=lgb.LGBMClassifier(objective=\"binary\", random_state=42, **lgb_params)\n",
    "\n",
    "vt_clf = VotingClassifier(estimators = [\n",
    "        ('lgbm', tuned_lgbm),\n",
    "        ('rf', rf_clf),\n",
    "        ('ex', ex_clf),\n",
    "    ], weights = (2, 1, 7), voting = 'soft')\n",
    "\n",
    "score = cross_val_score(vt_clf, X, y, cv = 10, scoring = 'roc_auc')\n",
    "score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nerdiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.796669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.884768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.577233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.956298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35447</th>\n",
       "      <td>35447</td>\n",
       "      <td>0.959114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35448</th>\n",
       "      <td>35448</td>\n",
       "      <td>0.739745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35449</th>\n",
       "      <td>35449</td>\n",
       "      <td>0.951074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35450</th>\n",
       "      <td>35450</td>\n",
       "      <td>0.056970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35451</th>\n",
       "      <td>35451</td>\n",
       "      <td>0.697638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35452 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  nerdiness\n",
       "0          0   0.093751\n",
       "1          1   0.796669\n",
       "2          2   0.884768\n",
       "3          3   0.577233\n",
       "4          4   0.956298\n",
       "...      ...        ...\n",
       "35447  35447   0.959114\n",
       "35448  35448   0.739745\n",
       "35449  35449   0.951074\n",
       "35450  35450   0.056970\n",
       "35451  35451   0.697638\n",
       "\n",
       "[35452 rows x 2 columns]"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier, RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "ex_params = {'n_estimators': 500, 'max_depth': 75, 'max_features': 0.20222465942018208, 'criterion': 'entropy'}\n",
    "rf_params =  {'n_estimators': 400, 'max_depth': 31, 'max_features': 0.05408093225447195, 'criterion': 'entropy'}\n",
    "lgb_params = {'n_estimators': 189, 'learning_rate': 0.06550029428021084, 'num_leaves': 249, 'reg_alpha': 0.00011906936480932443, 'reg_lambda': 0.00012169645168232884, 'colsample_bytree': 0.2231374650653746, 'subsample': 0.18089704448751198}\n",
    "\n",
    "ex_clf = ExtraTreesClassifier(**ex_params, random_state = 42)\n",
    "rf_clf = RandomForestClassifier(**rf_params, random_state = 42)\n",
    "tuned_lgbm=lgb.LGBMClassifier(objective=\"binary\", random_state=42, **lgb_params)\n",
    "\n",
    "vt_clf = VotingClassifier(estimators = [\n",
    "        ('lgbm', tuned_lgbm),\n",
    "        ('rf', rf_clf),\n",
    "        ('ex', ex_clf),\n",
    "    ], weights = (2, 1, 7), voting = 'soft')\n",
    "\n",
    "vt_clf.fit(X, y)\n",
    "\n",
    "predictions = vt_clf.predict_proba(test_data)[:, 1]\n",
    "submission['nerdiness'] = predictions\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna\n",
    "# optuna를 사용하여 하이퍼 파라미터 최적화\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def tune_model(model_type, X, Y, n_trials=100, cv=10):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    \n",
    "    if model_type=='lgb':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "            learning_rate = trial.suggest_loguniform('learning_rate', 0.05, 0.3)\n",
    "            num_leaves = trial.suggest_int('num_leaves', 7, 255)\n",
    "            reg_alpha = trial.suggest_loguniform('reg_alpha', 1e-4, 10)\n",
    "            reg_lambda = trial.suggest_loguniform('reg_lambda', 1e-4, 10)\n",
    "            colsample_bytree = trial.suggest_uniform('colsample_bytree', 0, 1)\n",
    "            subsample = trial.suggest_uniform('subsample', 0, 1)\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'learning_rate' : learning_rate, \n",
    "                      'num_leaves' : num_leaves,\n",
    "                     'reg_alpha' : reg_alpha,\n",
    "                     'reg_lambda' : reg_lambda, \n",
    "                     'colsample_bytree' : colsample_bytree, \n",
    "                     'subsample' : subsample\n",
    "                     }\n",
    "            model = lgb.LGBMClassifier(metric='auc', random_state=42, **params)\n",
    "            score = cross_val_score(model, X, Y, cv=skf, scoring='roc_auc').mean()\n",
    "            \n",
    "            return score\n",
    "    \n",
    "#     elif model_type=='cat':\n",
    "#         def objective(trial):\n",
    "#             params={}\n",
    "#             params['n_estimators'] = trial.suggest_int('n_estimators', 100, 1000)\n",
    "#             params['learning_rate'] = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "#             params['depth'] = trial.suggest_int('depth', 3, 8)\n",
    "#             params['reg_lambda'] = trial.suggest_loguniform('reg_lambda', 1e-4, 30)\n",
    "#             params['random_strength'] = trial.suggest_uniform('random_strength', 0.1, 30)\n",
    "            \n",
    "#             params['bootstrap_type'] = trial.suggest_categorical('bootstrap_type', ['Bayesian','Bernoulli','Poisson'])\n",
    "#             if params['bootstrap_type'] == 'Bayesian':\n",
    "#                 params['bagging_temperature'] = trial.suggest_uniform('bagging_temperature', 0, 30)\n",
    "#             else: \n",
    "#                 params['subsample'] = trial.suggest_uniform('subsample', 0, 1)\n",
    "#             print(params)\n",
    "#             model = CatBoostClassifier(task_type=\"GPU\", eval_metric='AUC', random_seed=42, **params, verbose=False)\n",
    "#             model.fit(x_train, y_train, early_stopping_rounds=100, verbose=500, eval_set=(x_test, y_test))\n",
    "#             score = roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "\n",
    "#             return score\n",
    "        \n",
    "        \n",
    "    elif model_type=='rf':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 100)\n",
    "            max_features = trial.suggest_uniform('max_features', 0, 1)\n",
    "            criterion = trial.suggest_categorical('criterion', ['gini','entropy'])\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'max_features' : max_features, \n",
    "                      'max_depth' : max_depth,\n",
    "                      'criterion' : criterion\n",
    "                     }\n",
    "            model = RandomForestClassifier(random_state=42, **params, n_jobs=-1)\n",
    "            score = cross_val_score(model, X, Y, cv=skf, scoring='roc_auc').mean()\n",
    "            \n",
    "            return score\n",
    "        \n",
    "        \n",
    "    elif model_type=='ets':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 100)\n",
    "            max_features = trial.suggest_uniform('max_features', 0, 1)\n",
    "            criterion = trial.suggest_categorical('criterion', ['gini','entropy'])\n",
    "            params = {'n_estimators' : n_estimators, \n",
    "                     'max_features' : max_features, \n",
    "                      'max_depth' : max_depth,\n",
    "                      'criterion' : criterion\n",
    "                     }\n",
    "            model = ExtraTreesClassifier(random_state=42, **params, n_jobs=-1)\n",
    "            score = cross_val_score(model, X, Y, cv=skf, scoring='roc_auc').mean()\n",
    "            \n",
    "            return score\n",
    "        \n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    study=optuna.create_study(direction='maximize', \n",
    "                              sampler = sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    print(f\"Model : {model_type}, Best Score : {study.best_value}, Best Params : {study.best_params}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-11 00:32:44,280]\u001b[0m Trial 0 finished with value: 0.8270957717078261 and parameters: {'n_estimators': 202, 'learning_rate': 0.2083535600888856, 'num_leaves': 21, 'reg_alpha': 0.4570563099801455, 'reg_lambda': 0.09846738873614563, 'colsample_bytree': 0.15601864044243652, 'subsample': 0.15599452033620265}. Best is trial 0 with value: 0.8270957717078261.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:32:51,839]\u001b[0m Trial 1 finished with value: 0.7986779746086973 and parameters: {'n_estimators': 430, 'learning_rate': 0.1138505423634207, 'num_leaves': 123, 'reg_alpha': 0.10129197956845731, 'reg_lambda': 0.3470266988650412, 'colsample_bytree': 0.020584494295802447, 'subsample': 0.9699098521619943}. Best is trial 0 with value: 0.8270957717078261.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:33:48,778]\u001b[0m Trial 2 finished with value: 0.8802643601186138 and parameters: {'n_estimators': 591, 'learning_rate': 0.26872369865333173, 'num_leaves': 136, 'reg_alpha': 0.0008111941985431928, 'reg_lambda': 0.0008260808399079611, 'colsample_bytree': 0.3042422429595377, 'subsample': 0.5247564316322378}. Best is trial 2 with value: 0.8802643601186138.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:35:45,638]\u001b[0m Trial 3 finished with value: 0.8832985546489642 and parameters: {'n_estimators': 847, 'learning_rate': 0.05210939839135199, 'num_leaves': 225, 'reg_alpha': 0.11462107403425033, 'reg_lambda': 0.0004982752357076451, 'colsample_bytree': 0.29214464853521815, 'subsample': 0.3663618432936917}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:36:29,377]\u001b[0m Trial 4 finished with value: 0.8777413906675614 and parameters: {'n_estimators': 289, 'learning_rate': 0.05881329545207103, 'num_leaves': 196, 'reg_alpha': 0.0009962513222055108, 'reg_lambda': 0.03725393839578886, 'colsample_bytree': 0.5924145688620425, 'subsample': 0.046450412719997725}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:37:44,221]\u001b[0m Trial 5 finished with value: 0.8713057856797934 and parameters: {'n_estimators': 918, 'learning_rate': 0.1691812253420456, 'num_leaves': 79, 'reg_alpha': 0.00021147447960615738, 'reg_lambda': 5.5517216852447255, 'colsample_bytree': 0.9656320330745594, 'subsample': 0.8083973481164611}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:38:57,485]\u001b[0m Trial 6 finished with value: 0.8742487960193079 and parameters: {'n_estimators': 876, 'learning_rate': 0.051451040676901746, 'num_leaves': 136, 'reg_alpha': 0.2637333993381525, 'reg_lambda': 0.015876781526923997, 'colsample_bytree': 0.12203823484477883, 'subsample': 0.4951769101112702}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:39:15,483]\u001b[0m Trial 7 finished with value: 0.8705636814579012 and parameters: {'n_estimators': 134, 'learning_rate': 0.25501094005511254, 'num_leaves': 170, 'reg_alpha': 0.000815042844436478, 'reg_lambda': 0.598145791725076, 'colsample_bytree': 0.4251558744912447, 'subsample': 0.20794166286818883}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:40:26,621]\u001b[0m Trial 8 finished with value: 0.8720979429882048 and parameters: {'n_estimators': 871, 'learning_rate': 0.06963293967288252, 'num_leaves': 197, 'reg_alpha': 1.6271360716645846, 'reg_lambda': 0.017732528513177907, 'colsample_bytree': 0.3951502360018144, 'subsample': 0.9266588657937942}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:41:10,036]\u001b[0m Trial 9 finished with value: 0.8755787511324815 and parameters: {'n_estimators': 962, 'learning_rate': 0.2608120141371272, 'num_leaves': 206, 'reg_alpha': 0.07115736737626971, 'reg_lambda': 0.0401949321712464, 'colsample_bytree': 0.9611720243493491, 'subsample': 0.8445338486781514}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:42:58,182]\u001b[0m Trial 10 finished with value: 0.8828499166250208 and parameters: {'n_estimators': 698, 'learning_rate': 0.08832488695149782, 'num_leaves': 248, 'reg_alpha': 0.00872577592728182, 'reg_lambda': 0.0001353271850058773, 'colsample_bytree': 0.6801124141701534, 'subsample': 0.4462735374959945}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:44:41,184]\u001b[0m Trial 11 finished with value: 0.8811195535461097 and parameters: {'n_estimators': 676, 'learning_rate': 0.09294466688502799, 'num_leaves': 253, 'reg_alpha': 0.011614722045417327, 'reg_lambda': 0.00012840135020774523, 'colsample_bytree': 0.6751062233484583, 'subsample': 0.43109575213946544}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:46:44,376]\u001b[0m Trial 12 finished with value: 0.8821729105877724 and parameters: {'n_estimators': 723, 'learning_rate': 0.08067322925476261, 'num_leaves': 246, 'reg_alpha': 0.008883489107364861, 'reg_lambda': 0.00019766311881687165, 'colsample_bytree': 0.7518534729867673, 'subsample': 0.34049472900524824}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:48:12,099]\u001b[0m Trial 13 finished with value: 0.8809920854170059 and parameters: {'n_estimators': 728, 'learning_rate': 0.14023775475482975, 'num_leaves': 254, 'reg_alpha': 0.011288380469747894, 'reg_lambda': 0.0016757641918941327, 'colsample_bytree': 0.8263356679220775, 'subsample': 0.6455041426296283}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:49:26,889]\u001b[0m Trial 14 finished with value: 0.881472964181557 and parameters: {'n_estimators': 477, 'learning_rate': 0.050427896466867975, 'num_leaves': 222, 'reg_alpha': 0.003957454742408409, 'reg_lambda': 0.0018771432729821837, 'colsample_bytree': 0.5120009609603315, 'subsample': 0.2841983167838522}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:50:01,621]\u001b[0m Trial 15 finished with value: 0.8544553291868932 and parameters: {'n_estimators': 803, 'learning_rate': 0.09824325850186713, 'num_leaves': 231, 'reg_alpha': 3.5978277307948385, 'reg_lambda': 0.00039065556824826854, 'colsample_bytree': 0.2516514559189421, 'subsample': 0.6423620561394953}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:51:10,227]\u001b[0m Trial 16 finished with value: 0.8825257408174497 and parameters: {'n_estimators': 604, 'learning_rate': 0.06418235649113684, 'num_leaves': 172, 'reg_alpha': 0.038954693696494826, 'reg_lambda': 0.0049105269375362545, 'colsample_bytree': 0.5815238407883252, 'subsample': 0.013179214380923843}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:51:33,549]\u001b[0m Trial 17 finished with value: 0.8266393167927854 and parameters: {'n_estimators': 988, 'learning_rate': 0.079112636020064, 'num_leaves': 7, 'reg_alpha': 0.3808190807380823, 'reg_lambda': 0.0001351795848114824, 'colsample_bytree': 0.7987371400684047, 'subsample': 0.3610411220249553}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:52:19,972]\u001b[0m Trial 18 finished with value: 0.8750381479615195 and parameters: {'n_estimators': 804, 'learning_rate': 0.1340899741363157, 'num_leaves': 68, 'reg_alpha': 0.002202762754957708, 'reg_lambda': 0.000589384340859191, 'colsample_bytree': 0.3037491187761712, 'subsample': 0.5902817209847522}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:52:44,732]\u001b[0m Trial 19 finished with value: 0.8362811365242176 and parameters: {'n_estimators': 500, 'learning_rate': 0.05159670887767495, 'num_leaves': 160, 'reg_alpha': 9.460877097455866, 'reg_lambda': 0.0048646222549397, 'colsample_bytree': 0.6660954461605317, 'subsample': 0.16085597852116001}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:52:49,086]\u001b[0m Trial 20 finished with value: 0.7952918234478692 and parameters: {'n_estimators': 344, 'learning_rate': 0.10441543491264663, 'num_leaves': 225, 'reg_alpha': 0.025129687220576995, 'reg_lambda': 0.00011431541785080464, 'colsample_bytree': 0.010750659975261367, 'subsample': 0.41447517600809114}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:54:14,764]\u001b[0m Trial 21 finished with value: 0.8805929778792663 and parameters: {'n_estimators': 615, 'learning_rate': 0.06427422940357885, 'num_leaves': 176, 'reg_alpha': 0.052678615580898085, 'reg_lambda': 0.004592855844753474, 'colsample_bytree': 0.5419612925465128, 'subsample': 0.004123227447912081}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:55:26,528]\u001b[0m Trial 22 finished with value: 0.8812735559698031 and parameters: {'n_estimators': 640, 'learning_rate': 0.07623691191811159, 'num_leaves': 209, 'reg_alpha': 0.16161857549567207, 'reg_lambda': 0.0033104106999335453, 'colsample_bytree': 0.4571726917164998, 'subsample': 0.07631707713634772}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:56:42,547]\u001b[0m Trial 23 finished with value: 0.8829246847774955 and parameters: {'n_estimators': 782, 'learning_rate': 0.05851071656792121, 'num_leaves': 178, 'reg_alpha': 0.022433724678106667, 'reg_lambda': 0.00034007554563133115, 'colsample_bytree': 0.623658959149873, 'subsample': 0.2577624171113715}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 00:58:42,380]\u001b[0m Trial 24 finished with value: 0.8822608214466732 and parameters: {'n_estimators': 787, 'learning_rate': 0.05884629111440962, 'num_leaves': 237, 'reg_alpha': 0.01891732885991259, 'reg_lambda': 0.0002764446934973138, 'colsample_bytree': 0.8628985838342584, 'subsample': 0.25816420736456247}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:00:46,769]\u001b[0m Trial 25 finished with value: 0.8823152433142273 and parameters: {'n_estimators': 729, 'learning_rate': 0.08777257895528053, 'num_leaves': 191, 'reg_alpha': 0.0038416395108357175, 'reg_lambda': 0.000963399542987143, 'colsample_bytree': 0.6724821006881604, 'subsample': 0.3302763975170939}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:02:22,627]\u001b[0m Trial 26 finished with value: 0.877220921716271 and parameters: {'n_estimators': 863, 'learning_rate': 0.058820309009215636, 'num_leaves': 147, 'reg_alpha': 0.6831449875223816, 'reg_lambda': 0.0003789505652537112, 'colsample_bytree': 0.35209599481243203, 'subsample': 0.4485953660907055}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:03:39,856]\u001b[0m Trial 27 finished with value: 0.8815928243022944 and parameters: {'n_estimators': 778, 'learning_rate': 0.06830766162765979, 'num_leaves': 118, 'reg_alpha': 0.00022010172339327228, 'reg_lambda': 0.00010013199616359708, 'colsample_bytree': 0.7409689126517802, 'subsample': 0.5323770088371775}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:05:57,917]\u001b[0m Trial 28 finished with value: 0.8793490011829335 and parameters: {'n_estimators': 540, 'learning_rate': 0.05104151226392537, 'num_leaves': 216, 'reg_alpha': 0.14506419805082188, 'reg_lambda': 0.0008835384337884981, 'colsample_bytree': 0.1768521499135366, 'subsample': 0.25611834745021556}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:07:35,526]\u001b[0m Trial 29 finished with value: 0.870490326896714 and parameters: {'n_estimators': 943, 'learning_rate': 0.15685770018616574, 'num_leaves': 188, 'reg_alpha': 0.9668052324956403, 'reg_lambda': 8.059145444618471, 'colsample_bytree': 0.6158223400390055, 'subsample': 0.16789585990881573}. Best is trial 3 with value: 0.8832985546489642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:11:30,547]\u001b[0m Trial 30 finished with value: 0.8839630247345702 and parameters: {'n_estimators': 689, 'learning_rate': 0.0850400441426623, 'num_leaves': 242, 'reg_alpha': 0.004531740663842783, 'reg_lambda': 0.0002641703924214369, 'colsample_bytree': 0.4748110086545946, 'subsample': 0.09846063467988364}. Best is trial 30 with value: 0.8839630247345702.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:14:13,339]\u001b[0m Trial 31 finished with value: 0.8827119635135544 and parameters: {'n_estimators': 695, 'learning_rate': 0.11178606143898377, 'num_leaves': 253, 'reg_alpha': 0.006458682186536883, 'reg_lambda': 0.00024340540225249626, 'colsample_bytree': 0.4762381317977874, 'subsample': 0.10794005791845143}. Best is trial 30 with value: 0.8839630247345702.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:17:11,852]\u001b[0m Trial 32 finished with value: 0.8837758177717895 and parameters: {'n_estimators': 841, 'learning_rate': 0.0856256714200446, 'num_leaves': 232, 'reg_alpha': 0.0020065587663276744, 'reg_lambda': 0.00010422237509740989, 'colsample_bytree': 0.5342760008935802, 'subsample': 0.38054796875589403}. Best is trial 30 with value: 0.8839630247345702.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:19:54,516]\u001b[0m Trial 33 finished with value: 0.8852208144299171 and parameters: {'n_estimators': 840, 'learning_rate': 0.07572693182666147, 'num_leaves': 232, 'reg_alpha': 0.001506487841747175, 'reg_lambda': 0.0018237747820828568, 'colsample_bytree': 0.37658462269236515, 'subsample': 0.22217471275047082}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:22:37,775]\u001b[0m Trial 34 finished with value: 0.8843769066723215 and parameters: {'n_estimators': 846, 'learning_rate': 0.12009262268407886, 'num_leaves': 234, 'reg_alpha': 0.000380949510405075, 'reg_lambda': 0.0018524395106763408, 'colsample_bytree': 0.22051714690592517, 'subsample': 0.12651380589906402}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:25:19,809]\u001b[0m Trial 35 finished with value: 0.8849991561374061 and parameters: {'n_estimators': 913, 'learning_rate': 0.12428881313751748, 'num_leaves': 236, 'reg_alpha': 0.00010741963707415954, 'reg_lambda': 0.0016263592273770076, 'colsample_bytree': 0.23323385420878798, 'subsample': 0.11347249681658153}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:28:09,180]\u001b[0m Trial 36 finished with value: 0.8831052414373823 and parameters: {'n_estimators': 909, 'learning_rate': 0.11965710956411735, 'num_leaves': 239, 'reg_alpha': 0.0001169910561968974, 'reg_lambda': 0.010363787038131898, 'colsample_bytree': 0.21124487854575202, 'subsample': 0.09706168961873239}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:30:19,233]\u001b[0m Trial 37 finished with value: 0.8771104735180183 and parameters: {'n_estimators': 991, 'learning_rate': 0.18239570772042793, 'num_leaves': 212, 'reg_alpha': 0.0004292677172864668, 'reg_lambda': 0.0021568827753128384, 'colsample_bytree': 0.08120179655939433, 'subsample': 0.12612988528553323}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:31:54,718]\u001b[0m Trial 38 finished with value: 0.8795546899991773 and parameters: {'n_estimators': 916, 'learning_rate': 0.12779037187467399, 'num_leaves': 94, 'reg_alpha': 0.000385000520206673, 'reg_lambda': 0.07828428090917038, 'colsample_bytree': 0.3494082761659348, 'subsample': 0.19907661989342262}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:33:23,472]\u001b[0m Trial 39 finished with value: 0.8765898952571346 and parameters: {'n_estimators': 844, 'learning_rate': 0.14839666711871294, 'num_leaves': 203, 'reg_alpha': 0.00010731958556091739, 'reg_lambda': 0.008975382830315773, 'colsample_bytree': 0.07827324172708616, 'subsample': 0.0018675675889474608}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:34:00,749]\u001b[0m Trial 40 finished with value: 0.8703609194012516 and parameters: {'n_estimators': 997, 'learning_rate': 0.20613107731161429, 'num_leaves': 44, 'reg_alpha': 0.001655324899183569, 'reg_lambda': 0.34507387584904686, 'colsample_bytree': 0.24645246896537157, 'subsample': 0.05663147503218102}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:35:55,441]\u001b[0m Trial 41 finished with value: 0.8840043234284494 and parameters: {'n_estimators': 825, 'learning_rate': 0.10629705163913719, 'num_leaves': 233, 'reg_alpha': 0.0013105365560507622, 'reg_lambda': 0.0009234354639345567, 'colsample_bytree': 0.38240212255215533, 'subsample': 0.20208615829798415}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:37:45,404]\u001b[0m Trial 42 finished with value: 0.8851598536482603 and parameters: {'n_estimators': 758, 'learning_rate': 0.10966790611613021, 'num_leaves': 236, 'reg_alpha': 0.0004234334265727399, 'reg_lambda': 0.0012586515030044523, 'colsample_bytree': 0.3875461220462384, 'subsample': 0.20108569296187678}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:39:46,080]\u001b[0m Trial 43 finished with value: 0.8847946646367276 and parameters: {'n_estimators': 884, 'learning_rate': 0.10499624308059287, 'num_leaves': 220, 'reg_alpha': 0.0005306292266264278, 'reg_lambda': 0.001208726203968093, 'colsample_bytree': 0.38941180089991456, 'subsample': 0.21367678504017112}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:41:58,971]\u001b[0m Trial 44 finished with value: 0.8849915897385514 and parameters: {'n_estimators': 897, 'learning_rate': 0.09749446766780787, 'num_leaves': 254, 'reg_alpha': 0.00045129107926645217, 'reg_lambda': 0.0012623776376211619, 'colsample_bytree': 0.27462545975600205, 'subsample': 0.30294400274510846}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:44:18,832]\u001b[0m Trial 45 finished with value: 0.8850451521197689 and parameters: {'n_estimators': 945, 'learning_rate': 0.0970922647669184, 'num_leaves': 255, 'reg_alpha': 0.0006569915367957091, 'reg_lambda': 0.0006095167590614774, 'colsample_bytree': 0.3217911103155618, 'subsample': 0.2813718111354094}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:46:28,658]\u001b[0m Trial 46 finished with value: 0.8841288643331474 and parameters: {'n_estimators': 956, 'learning_rate': 0.09662448741989099, 'num_leaves': 254, 'reg_alpha': 0.00018375787444537675, 'reg_lambda': 0.003067602349654715, 'colsample_bytree': 0.15174751408245915, 'subsample': 0.30384313374829885}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:48:45,480]\u001b[0m Trial 47 finished with value: 0.8852068922775409 and parameters: {'n_estimators': 913, 'learning_rate': 0.07431551146163341, 'num_leaves': 255, 'reg_alpha': 0.0007763970649710839, 'reg_lambda': 0.008140427891399855, 'colsample_bytree': 0.27590653914627783, 'subsample': 0.23062870773322144}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:52:08,431]\u001b[0m Trial 48 finished with value: 0.8847916762179822 and parameters: {'n_estimators': 762, 'learning_rate': 0.0743403527684226, 'num_leaves': 245, 'reg_alpha': 0.0007748121557250524, 'reg_lambda': 0.020242951275494147, 'colsample_bytree': 0.32475714994955823, 'subsample': 0.23799312452770996}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:54:12,803]\u001b[0m Trial 49 finished with value: 0.8843898609101954 and parameters: {'n_estimators': 943, 'learning_rate': 0.11343331226606103, 'num_leaves': 200, 'reg_alpha': 0.00019552040002677125, 'reg_lambda': 0.008747754857174187, 'colsample_bytree': 0.4167991128747318, 'subsample': 0.16161005606191808}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:56:27,965]\u001b[0m Trial 50 finished with value: 0.8843648241588763 and parameters: {'n_estimators': 994, 'learning_rate': 0.07109820888346603, 'num_leaves': 224, 'reg_alpha': 0.0008163949389421105, 'reg_lambda': 0.0007162540325245908, 'colsample_bytree': 0.3009436153119875, 'subsample': 0.1888548791849581}. Best is trial 33 with value: 0.8852208144299171.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 01:58:40,604]\u001b[0m Trial 51 finished with value: 0.8861411044816881 and parameters: {'n_estimators': 903, 'learning_rate': 0.09773333193736991, 'num_leaves': 253, 'reg_alpha': 0.00026509139616467405, 'reg_lambda': 0.0013802165150276573, 'colsample_bytree': 0.2597676540349027, 'subsample': 0.30426462911595864}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:00:47,658]\u001b[0m Trial 52 finished with value: 0.8839123472411098 and parameters: {'n_estimators': 926, 'learning_rate': 0.09061187796118193, 'num_leaves': 246, 'reg_alpha': 0.0001438527675705787, 'reg_lambda': 0.0026252339007841, 'colsample_bytree': 0.19175680747061136, 'subsample': 0.29441168663986805}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:02:51,857]\u001b[0m Trial 53 finished with value: 0.8831223428706572 and parameters: {'n_estimators': 883, 'learning_rate': 0.08139480646670201, 'num_leaves': 255, 'reg_alpha': 0.00029753391904573074, 'reg_lambda': 0.0005175208049260159, 'colsample_bytree': 0.14047149458638833, 'subsample': 0.23826174820915405}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:04:55,315]\u001b[0m Trial 54 finished with value: 0.8849515790282106 and parameters: {'n_estimators': 965, 'learning_rate': 0.1291698556762383, 'num_leaves': 227, 'reg_alpha': 0.0007792437648636788, 'reg_lambda': 0.006995989991231635, 'colsample_bytree': 0.26143826212175275, 'subsample': 0.3927815166965064}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:06:59,785]\u001b[0m Trial 55 finished with value: 0.8841855916239563 and parameters: {'n_estimators': 820, 'learning_rate': 0.09396863140679376, 'num_leaves': 244, 'reg_alpha': 0.001205882258569277, 'reg_lambda': 0.03051130011836446, 'colsample_bytree': 0.34073351219667275, 'subsample': 0.031577682441288724}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:08:30,118]\u001b[0m Trial 56 finished with value: 0.8826938664608205 and parameters: {'n_estimators': 751, 'learning_rate': 0.1426029069165989, 'num_leaves': 212, 'reg_alpha': 0.002552175359069572, 'reg_lambda': 0.0014719409961349245, 'colsample_bytree': 0.4353754626322329, 'subsample': 0.3407757101237285}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:10:39,099]\u001b[0m Trial 57 finished with value: 0.885686056596235 and parameters: {'n_estimators': 967, 'learning_rate': 0.10355066571905856, 'num_leaves': 240, 'reg_alpha': 0.00010147689104365562, 'reg_lambda': 0.004086084989383195, 'colsample_bytree': 0.23515439492882617, 'subsample': 0.13695269514441882}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:12:40,164]\u001b[0m Trial 58 finished with value: 0.8849495412845446 and parameters: {'n_estimators': 972, 'learning_rate': 0.10902989608262281, 'num_leaves': 219, 'reg_alpha': 0.0002577358258922938, 'reg_lambda': 0.004417037521516848, 'colsample_bytree': 0.29220201437451865, 'subsample': 0.4823339321454647}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:14:17,224]\u001b[0m Trial 59 finished with value: 0.8786630784271395 and parameters: {'n_estimators': 882, 'learning_rate': 0.10013853735099702, 'num_leaves': 249, 'reg_alpha': 0.0007243458826386068, 'reg_lambda': 0.01435428392574545, 'colsample_bytree': 0.09857068786299489, 'subsample': 0.15270020508928206}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:15:14,775]\u001b[0m Trial 60 finished with value: 0.8837031941227427 and parameters: {'n_estimators': 387, 'learning_rate': 0.07773926167175702, 'num_leaves': 254, 'reg_alpha': 0.0005709744986073538, 'reg_lambda': 0.00616705251267878, 'colsample_bytree': 0.37289314084379216, 'subsample': 0.2809093243810318}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:17:11,608]\u001b[0m Trial 61 finished with value: 0.8843115734603595 and parameters: {'n_estimators': 926, 'learning_rate': 0.11756015093516826, 'num_leaves': 238, 'reg_alpha': 0.0001106093507960537, 'reg_lambda': 0.0005988409979920077, 'colsample_bytree': 0.32239984457644105, 'subsample': 0.21916608141517008}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:17:36,385]\u001b[0m Trial 62 finished with value: 0.8734071855030582 and parameters: {'n_estimators': 186, 'learning_rate': 0.08226065827973056, 'num_leaves': 230, 'reg_alpha': 0.0001579656875512903, 'reg_lambda': 0.003004540781641479, 'colsample_bytree': 0.22577857655710523, 'subsample': 0.14307838717910387}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:19:30,299]\u001b[0m Trial 63 finished with value: 0.8842845146965053 and parameters: {'n_estimators': 864, 'learning_rate': 0.10105282662746322, 'num_leaves': 238, 'reg_alpha': 0.00028244109651012674, 'reg_lambda': 0.00185677886124878, 'colsample_bytree': 0.26153904766302355, 'subsample': 0.06323406175791027}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:21:25,504]\u001b[0m Trial 64 finished with value: 0.883076491454007 and parameters: {'n_estimators': 903, 'learning_rate': 0.12420055090823869, 'num_leaves': 255, 'reg_alpha': 0.0011562797903729165, 'reg_lambda': 0.004090040785466814, 'colsample_bytree': 0.183362609656761, 'subsample': 0.17568395397065942}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:23:14,529]\u001b[0m Trial 65 finished with value: 0.8846933576088295 and parameters: {'n_estimators': 810, 'learning_rate': 0.09223652612034365, 'num_leaves': 228, 'reg_alpha': 0.0002880840936259368, 'reg_lambda': 0.0012595088228616045, 'colsample_bytree': 0.4005789870981082, 'subsample': 0.3340861154786976}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:25:11,201]\u001b[0m Trial 66 finished with value: 0.8847864434661676 and parameters: {'n_estimators': 945, 'learning_rate': 0.07257725089617716, 'num_leaves': 216, 'reg_alpha': 0.00010761050217898861, 'reg_lambda': 0.0003939428978039063, 'colsample_bytree': 0.3602378787759345, 'subsample': 0.2349617941724797}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:25:45,632]\u001b[0m Trial 67 finished with value: 0.8418433134925548 and parameters: {'n_estimators': 651, 'learning_rate': 0.0664582139074495, 'num_leaves': 185, 'reg_alpha': 0.00015474974820916772, 'reg_lambda': 0.0001869387622488519, 'colsample_bytree': 0.04675728332824103, 'subsample': 0.09009867517231601}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:27:19,723]\u001b[0m Trial 68 finished with value: 0.8831846799545392 and parameters: {'n_estimators': 998, 'learning_rate': 0.13451077897457311, 'num_leaves': 245, 'reg_alpha': 0.0027736163126925203, 'reg_lambda': 0.0022096585107171107, 'colsample_bytree': 0.43555540537354437, 'subsample': 0.12873562583830356}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:29:08,802]\u001b[0m Trial 69 finished with value: 0.8839840819783827 and parameters: {'n_estimators': 966, 'learning_rate': 0.06236252286156346, 'num_leaves': 205, 'reg_alpha': 0.00023234214040582205, 'reg_lambda': 0.012678925037288864, 'colsample_bytree': 0.23577741904557212, 'subsample': 0.266174385185456}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:30:44,311]\u001b[0m Trial 70 finished with value: 0.8840290068856156 and parameters: {'n_estimators': 863, 'learning_rate': 0.05552393238207824, 'num_leaves': 196, 'reg_alpha': 0.0005881493468946061, 'reg_lambda': 0.006321503601831183, 'colsample_bytree': 0.28658403442325353, 'subsample': 0.7398873980403553}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:32:49,322]\u001b[0m Trial 71 finished with value: 0.8852458222746277 and parameters: {'n_estimators': 888, 'learning_rate': 0.09817389971289901, 'num_leaves': 249, 'reg_alpha': 0.0003895907664231424, 'reg_lambda': 0.0012023087307554824, 'colsample_bytree': 0.28087430767775484, 'subsample': 0.3087737308369196}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:34:55,946]\u001b[0m Trial 72 finished with value: 0.8853686878973029 and parameters: {'n_estimators': 926, 'learning_rate': 0.08901224204628144, 'num_leaves': 240, 'reg_alpha': 0.0003496582954825077, 'reg_lambda': 0.0007483078154724751, 'colsample_bytree': 0.33318139706026934, 'subsample': 0.31547118235432753}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:37:01,512]\u001b[0m Trial 73 finished with value: 0.88485305372162 and parameters: {'n_estimators': 932, 'learning_rate': 0.08674236528993186, 'num_leaves': 246, 'reg_alpha': 0.0016205425159376752, 'reg_lambda': 0.0007453309021550157, 'colsample_bytree': 0.31661447199243525, 'subsample': 0.35854580047280826}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:38:40,977]\u001b[0m Trial 74 finished with value: 0.8846002989376187 and parameters: {'n_estimators': 835, 'learning_rate': 0.09039371209725894, 'num_leaves': 224, 'reg_alpha': 0.0003403487587944714, 'reg_lambda': 0.0009754569633261592, 'colsample_bytree': 0.19743061608964785, 'subsample': 0.3103495846192023}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:40:36,567]\u001b[0m Trial 75 finished with value: 0.8843136848929605 and parameters: {'n_estimators': 792, 'learning_rate': 0.1028813975924932, 'num_leaves': 249, 'reg_alpha': 0.0005345760196249909, 'reg_lambda': 0.0005357430034733163, 'colsample_bytree': 0.5010175839989232, 'subsample': 0.4305743332019524}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:42:37,835]\u001b[0m Trial 76 finished with value: 0.8849838960616025 and parameters: {'n_estimators': 895, 'learning_rate': 0.07710381591396771, 'num_leaves': 237, 'reg_alpha': 0.001014702466285026, 'reg_lambda': 0.003937395309162638, 'colsample_bytree': 0.33132425799751397, 'subsample': 0.2654269387755778}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:44:38,193]\u001b[0m Trial 77 finished with value: 0.885477092415113 and parameters: {'n_estimators': 860, 'learning_rate': 0.08203824746343762, 'num_leaves': 255, 'reg_alpha': 0.00036506842802692935, 'reg_lambda': 0.002385763267293783, 'colsample_bytree': 0.2761325466410477, 'subsample': 0.3170552390618507}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:45:26,617]\u001b[0m Trial 78 finished with value: 0.8790876994848847 and parameters: {'n_estimators': 725, 'learning_rate': 0.10980057041775478, 'num_leaves': 118, 'reg_alpha': 0.00040995398655134936, 'reg_lambda': 0.002564831426979139, 'colsample_bytree': 0.16391375154080406, 'subsample': 0.37960574396994384}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:46:47,881]\u001b[0m Trial 79 finished with value: 0.8828875725971418 and parameters: {'n_estimators': 861, 'learning_rate': 0.0851395747087519, 'num_leaves': 160, 'reg_alpha': 0.00024106874589082883, 'reg_lambda': 0.02397465395462979, 'colsample_bytree': 0.2804601287848837, 'subsample': 0.4068920959339951}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:48:42,197]\u001b[0m Trial 80 finished with value: 0.8844304696784631 and parameters: {'n_estimators': 827, 'learning_rate': 0.06888656752953776, 'num_leaves': 231, 'reg_alpha': 0.00015022631699018252, 'reg_lambda': 0.0010009927924344755, 'colsample_bytree': 0.46057215354318487, 'subsample': 0.21270413059371476}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:50:53,589]\u001b[0m Trial 81 finished with value: 0.8851936156271666 and parameters: {'n_estimators': 978, 'learning_rate': 0.09556849590956402, 'num_leaves': 243, 'reg_alpha': 0.0006370759781553886, 'reg_lambda': 0.0014575955245856418, 'colsample_bytree': 0.3610712283796713, 'subsample': 0.3183791609007345}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:53:07,011]\u001b[0m Trial 82 finished with value: 0.8850350427224504 and parameters: {'n_estimators': 976, 'learning_rate': 0.08187087683862167, 'num_leaves': 240, 'reg_alpha': 0.00036393436150945334, 'reg_lambda': 0.0016717070562955448, 'colsample_bytree': 0.3566276824773592, 'subsample': 0.3238286076718667}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:55:04,948]\u001b[0m Trial 83 finished with value: 0.8834531281527653 and parameters: {'n_estimators': 913, 'learning_rate': 0.09439727790497184, 'num_leaves': 251, 'reg_alpha': 0.0015292995077108326, 'reg_lambda': 0.0013096280011673962, 'colsample_bytree': 0.24491898351754318, 'subsample': 0.35487206631243734}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:56:25,169]\u001b[0m Trial 84 finished with value: 0.8836212605680849 and parameters: {'n_estimators': 560, 'learning_rate': 0.11529318859211408, 'num_leaves': 243, 'reg_alpha': 0.0010518904641138712, 'reg_lambda': 0.0024351481817396076, 'colsample_bytree': 0.3963893944510697, 'subsample': 0.46349936796538627}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:58:02,291]\u001b[0m Trial 85 finished with value: 0.8846911744141419 and parameters: {'n_estimators': 760, 'learning_rate': 0.07490500446843668, 'num_leaves': 234, 'reg_alpha': 0.00046650383799903914, 'reg_lambda': 0.003765083650329495, 'colsample_bytree': 0.2684523533823054, 'subsample': 0.5288930936677187}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 02:59:20,067]\u001b[0m Trial 86 finished with value: 0.878900148129234 and parameters: {'n_estimators': 877, 'learning_rate': 0.29357784315481944, 'num_leaves': 221, 'reg_alpha': 0.00019029938317469182, 'reg_lambda': 0.00524215981972686, 'colsample_bytree': 0.30481024950917196, 'subsample': 0.19339143291838912}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:01:20,325]\u001b[0m Trial 87 finished with value: 0.8852623148179622 and parameters: {'n_estimators': 851, 'learning_rate': 0.08956843322051478, 'num_leaves': 249, 'reg_alpha': 0.0009189643988976237, 'reg_lambda': 0.0004168323557948509, 'colsample_bytree': 0.41301628664061407, 'subsample': 0.23604166442692937}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:03:23,685]\u001b[0m Trial 88 finished with value: 0.8843805841795657 and parameters: {'n_estimators': 854, 'learning_rate': 0.08860132059275755, 'num_leaves': 249, 'reg_alpha': 0.0008739658857129641, 'reg_lambda': 0.0004101054941850621, 'colsample_bytree': 0.42565975221400854, 'subsample': 0.23546017841735517}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:05:35,411]\u001b[0m Trial 89 finished with value: 0.882954817626737 and parameters: {'n_estimators': 899, 'learning_rate': 0.07901137505952835, 'num_leaves': 242, 'reg_alpha': 0.0036267621031617807, 'reg_lambda': 0.05117488028565875, 'colsample_bytree': 0.2094340041078577, 'subsample': 0.30440285869112504}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:07:48,448]\u001b[0m Trial 90 finished with value: 0.8809081160976078 and parameters: {'n_estimators': 939, 'learning_rate': 0.08155763840891446, 'num_leaves': 229, 'reg_alpha': 0.007001785986192424, 'reg_lambda': 0.00029800997437223455, 'colsample_bytree': 0.12468901043662098, 'subsample': 0.2687258267851146}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:09:23,199]\u001b[0m Trial 91 finished with value: 0.8857682925658306 and parameters: {'n_estimators': 809, 'learning_rate': 0.1063140651028103, 'num_leaves': 250, 'reg_alpha': 0.00033478435136824193, 'reg_lambda': 0.0010061766078073818, 'colsample_bytree': 0.3728046445955362, 'subsample': 0.1747330628195981}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:10:49,533]\u001b[0m Trial 92 finished with value: 0.8845741325746967 and parameters: {'n_estimators': 809, 'learning_rate': 0.09578171857013054, 'num_leaves': 250, 'reg_alpha': 0.002090035344239907, 'reg_lambda': 0.0007990691208770139, 'colsample_bytree': 0.36725719186597866, 'subsample': 0.17693430645919234}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:12:28,424]\u001b[0m Trial 93 finished with value: 0.8852614121057869 and parameters: {'n_estimators': 979, 'learning_rate': 0.1047515793203772, 'num_leaves': 255, 'reg_alpha': 0.0006437917062352223, 'reg_lambda': 0.00019820774755158045, 'colsample_bytree': 0.40641824926239106, 'subsample': 0.3215199737265152}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:13:58,039]\u001b[0m Trial 94 finished with value: 0.8845410101590753 and parameters: {'n_estimators': 836, 'learning_rate': 0.10603614993215811, 'num_leaves': 251, 'reg_alpha': 0.0003006132781342056, 'reg_lambda': 0.00017013014221638602, 'colsample_bytree': 0.41319692694374727, 'subsample': 0.23284821790528012}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:15:36,954]\u001b[0m Trial 95 finished with value: 0.8843957258824398 and parameters: {'n_estimators': 920, 'learning_rate': 0.10038608196002738, 'num_leaves': 254, 'reg_alpha': 0.00021474404284241847, 'reg_lambda': 0.000984613658290626, 'colsample_bytree': 0.46315381537169753, 'subsample': 0.24653024708882443}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:16:57,745]\u001b[0m Trial 96 finished with value: 0.8849963446781988 and parameters: {'n_estimators': 780, 'learning_rate': 0.08447519280852758, 'num_leaves': 242, 'reg_alpha': 0.0004957554646666535, 'reg_lambda': 0.00022515349220020626, 'colsample_bytree': 0.2994579915156659, 'subsample': 0.28980052028660386}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:18:28,333]\u001b[0m Trial 97 finished with value: 0.8856654005574027 and parameters: {'n_estimators': 880, 'learning_rate': 0.09021214322335716, 'num_leaves': 235, 'reg_alpha': 0.0009140834521206032, 'reg_lambda': 0.0004135600416847969, 'colsample_bytree': 0.3439570534211284, 'subsample': 0.9815100561196861}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:19:51,902]\u001b[0m Trial 98 finished with value: 0.8849959811788972 and parameters: {'n_estimators': 881, 'learning_rate': 0.09067695208389971, 'num_leaves': 215, 'reg_alpha': 0.00012955669523468866, 'reg_lambda': 0.00015621690852046297, 'colsample_bytree': 0.3431609431619355, 'subsample': 0.9657497335590856}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:21:25,940]\u001b[0m Trial 99 finished with value: 0.883576071890919 and parameters: {'n_estimators': 957, 'learning_rate': 0.10424390132995943, 'num_leaves': 234, 'reg_alpha': 0.0013753213897955171, 'reg_lambda': 0.0003240792943325479, 'colsample_bytree': 0.5465526000415697, 'subsample': 0.36701318881400424}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:22:46,234]\u001b[0m Trial 100 finished with value: 0.8835865484348691 and parameters: {'n_estimators': 797, 'learning_rate': 0.10036870427079746, 'num_leaves': 226, 'reg_alpha': 0.0009235063158199979, 'reg_lambda': 0.0004969693108798358, 'colsample_bytree': 0.4472550507310515, 'subsample': 0.821078115025363}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:24:19,352]\u001b[0m Trial 101 finished with value: 0.88514478152218 and parameters: {'n_estimators': 848, 'learning_rate': 0.08707174228076732, 'num_leaves': 255, 'reg_alpha': 0.0006809006885675384, 'reg_lambda': 0.0004491441446314962, 'colsample_bytree': 0.3803077056356081, 'subsample': 0.14268592878669606}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:25:48,322]\u001b[0m Trial 102 finished with value: 0.8849504116048349 and parameters: {'n_estimators': 888, 'learning_rate': 0.09259072548502358, 'num_leaves': 248, 'reg_alpha': 0.00035065052896535707, 'reg_lambda': 0.0006753813694826936, 'colsample_bytree': 0.2540949297238444, 'subsample': 0.28600697916204537}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:27:24,911]\u001b[0m Trial 103 finished with value: 0.8837407367213247 and parameters: {'n_estimators': 909, 'learning_rate': 0.11109405170734515, 'num_leaves': 239, 'reg_alpha': 0.0005371420593810557, 'reg_lambda': 0.0032072373822140425, 'colsample_bytree': 0.4873088256778735, 'subsample': 0.5690315227277731}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:28:59,812]\u001b[0m Trial 104 finished with value: 0.8851234181659636 and parameters: {'n_estimators': 863, 'learning_rate': 0.07144338980266726, 'num_leaves': 255, 'reg_alpha': 0.001912795460869691, 'reg_lambda': 0.0020544895641011114, 'colsample_bytree': 0.3092330631445452, 'subsample': 0.8830268893435735}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:30:37,896]\u001b[0m Trial 105 finished with value: 0.8847304520309311 and parameters: {'n_estimators': 945, 'learning_rate': 0.08871821246790022, 'num_leaves': 246, 'reg_alpha': 0.0011808830892885932, 'reg_lambda': 0.00024276839510735135, 'colsample_bytree': 0.33113915695874535, 'subsample': 0.3450139948281402}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:32:05,250]\u001b[0m Trial 106 finished with value: 0.8847264591936567 and parameters: {'n_estimators': 820, 'learning_rate': 0.07489172349566159, 'num_leaves': 232, 'reg_alpha': 0.0008160596052700425, 'reg_lambda': 0.0007930326849796286, 'colsample_bytree': 0.2801935261574104, 'subsample': 0.18124355299507122}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:33:10,833]\u001b[0m Trial 107 finished with value: 0.8765563171640061 and parameters: {'n_estimators': 926, 'learning_rate': 0.0831013346909768, 'num_leaves': 131, 'reg_alpha': 0.00018449699162415004, 'reg_lambda': 3.0421925514591686, 'colsample_bytree': 0.41218624026353806, 'subsample': 0.2210303190004685}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:34:27,862]\u001b[0m Trial 108 finished with value: 0.8844129750079871 and parameters: {'n_estimators': 873, 'learning_rate': 0.07948729770353725, 'num_leaves': 208, 'reg_alpha': 0.0029859479131706767, 'reg_lambda': 0.0016616850321833237, 'colsample_bytree': 0.2278702195812345, 'subsample': 0.4011385449011853}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:34:47,320]\u001b[0m Trial 109 finished with value: 0.8645823047042624 and parameters: {'n_estimators': 989, 'learning_rate': 0.10671897343974199, 'num_leaves': 26, 'reg_alpha': 0.0004543396843341731, 'reg_lambda': 0.0005981437828081255, 'colsample_bytree': 0.33526715807582275, 'subsample': 0.2641948569757905}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:35:24,514]\u001b[0m Trial 110 finished with value: 0.8788628131133986 and parameters: {'n_estimators': 898, 'learning_rate': 0.09921285170399394, 'num_leaves': 91, 'reg_alpha': 0.00026372260564408857, 'reg_lambda': 0.001128822090964548, 'colsample_bytree': 0.2018796637415571, 'subsample': 0.7510973769590956}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:37:05,741]\u001b[0m Trial 111 finished with value: 0.8852883222419236 and parameters: {'n_estimators': 982, 'learning_rate': 0.09553879491032272, 'num_leaves': 241, 'reg_alpha': 0.0006381695128347773, 'reg_lambda': 0.0016530424652844249, 'colsample_bytree': 0.36855549556129025, 'subsample': 0.3212124363524621}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:38:47,685]\u001b[0m Trial 112 finished with value: 0.8853057097360221 and parameters: {'n_estimators': 949, 'learning_rate': 0.0922552015450051, 'num_leaves': 238, 'reg_alpha': 0.0006492791612127864, 'reg_lambda': 0.0029941783345187947, 'colsample_bytree': 0.39454493632581544, 'subsample': 0.3719013526015264}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:40:25,783]\u001b[0m Trial 113 finished with value: 0.8857149401590197 and parameters: {'n_estimators': 957, 'learning_rate': 0.0911433699249586, 'num_leaves': 222, 'reg_alpha': 0.00033780754503479375, 'reg_lambda': 0.002654355208765548, 'colsample_bytree': 0.3928758581395962, 'subsample': 0.3792203483609898}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:42:07,867]\u001b[0m Trial 114 finished with value: 0.884319697923957 and parameters: {'n_estimators': 997, 'learning_rate': 0.0928369266556694, 'num_leaves': 221, 'reg_alpha': 0.000333656171552751, 'reg_lambda': 0.0026550617519595556, 'colsample_bytree': 0.40325522765464294, 'subsample': 0.3807384374999301}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:43:51,418]\u001b[0m Trial 115 finished with value: 0.884518304036272 and parameters: {'n_estimators': 959, 'learning_rate': 0.09732192007517021, 'num_leaves': 237, 'reg_alpha': 0.0006461720680855143, 'reg_lambda': 0.00012577299398004567, 'colsample_bytree': 0.5171889887490453, 'subsample': 0.3295366320491615}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:45:26,424]\u001b[0m Trial 116 finished with value: 0.8844375607127691 and parameters: {'n_estimators': 975, 'learning_rate': 0.10203089035075133, 'num_leaves': 228, 'reg_alpha': 0.00038636179875050746, 'reg_lambda': 0.0003305064860953784, 'colsample_bytree': 0.3824734086816526, 'subsample': 0.42821807860066924}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:47:05,520]\u001b[0m Trial 117 finished with value: 0.8853376234312181 and parameters: {'n_estimators': 933, 'learning_rate': 0.08948630616349945, 'num_leaves': 241, 'reg_alpha': 0.00022829814179492404, 'reg_lambda': 0.0014727977373697782, 'colsample_bytree': 0.34835204948394766, 'subsample': 0.37649252483525997}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:48:47,828]\u001b[0m Trial 118 finished with value: 0.8847744821378087 and parameters: {'n_estimators': 955, 'learning_rate': 0.09078199585115732, 'num_leaves': 240, 'reg_alpha': 0.00024345430706574627, 'reg_lambda': 0.0020887040658991232, 'colsample_bytree': 0.44232157947538836, 'subsample': 0.3571087632020426}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:50:19,826]\u001b[0m Trial 119 finished with value: 0.8848487148288934 and parameters: {'n_estimators': 936, 'learning_rate': 0.08596519238118745, 'num_leaves': 217, 'reg_alpha': 0.00010135597282293382, 'reg_lambda': 0.005000387393289927, 'colsample_bytree': 0.35350423434799094, 'subsample': 0.3782124059549435}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:52:01,132]\u001b[0m Trial 120 finished with value: 0.8849474274043253 and parameters: {'n_estimators': 981, 'learning_rate': 0.09411528654974931, 'num_leaves': 224, 'reg_alpha': 0.00016016057091831288, 'reg_lambda': 0.0033570003812148927, 'colsample_bytree': 0.3944340491771306, 'subsample': 0.49907169386618966}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:53:37,750]\u001b[0m Trial 121 finished with value: 0.8845481604049142 and parameters: {'n_estimators': 914, 'learning_rate': 0.09777127381984861, 'num_leaves': 247, 'reg_alpha': 0.00031798248001199984, 'reg_lambda': 0.0011889238420775604, 'colsample_bytree': 0.31316652593369854, 'subsample': 0.3155373447189126}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:55:17,668]\u001b[0m Trial 122 finished with value: 0.8851647470124175 and parameters: {'n_estimators': 998, 'learning_rate': 0.10738810096574598, 'num_leaves': 241, 'reg_alpha': 0.00047132333823760893, 'reg_lambda': 0.0015114350083662036, 'colsample_bytree': 0.3684475560376025, 'subsample': 0.4528651292543897}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:56:50,900]\u001b[0m Trial 123 finished with value: 0.884144136645102 and parameters: {'n_estimators': 928, 'learning_rate': 0.115166036383383, 'num_leaves': 235, 'reg_alpha': 0.0001988830567288739, 'reg_lambda': 0.0008724534485888908, 'colsample_bytree': 0.42154524267645915, 'subsample': 0.33568811006607174}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:58:27,510]\u001b[0m Trial 124 finished with value: 0.8843780658655931 and parameters: {'n_estimators': 956, 'learning_rate': 0.10307615604053796, 'num_leaves': 251, 'reg_alpha': 0.0006550887287497597, 'reg_lambda': 0.0007106270733544024, 'colsample_bytree': 0.33923493957245454, 'subsample': 0.3997740307065022}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 03:59:59,038]\u001b[0m Trial 125 finished with value: 0.8854924834143996 and parameters: {'n_estimators': 897, 'learning_rate': 0.0899854754638287, 'num_leaves': 245, 'reg_alpha': 0.0002584455949962741, 'reg_lambda': 0.0020363661268385856, 'colsample_bytree': 0.2663732322608079, 'subsample': 0.29203538031965803}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:00:28,428]\u001b[0m Trial 126 finished with value: 0.8790277359891505 and parameters: {'n_estimators': 278, 'learning_rate': 0.08848099127935938, 'num_leaves': 243, 'reg_alpha': 0.0002586865336778394, 'reg_lambda': 0.00262144858645155, 'colsample_bytree': 0.25452346084767485, 'subsample': 0.423436482902036}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:02:01,524]\u001b[0m Trial 127 finished with value: 0.8855079654442573 and parameters: {'n_estimators': 935, 'learning_rate': 0.08469455092863445, 'num_leaves': 231, 'reg_alpha': 0.0009861446874701444, 'reg_lambda': 0.0018384249113782465, 'colsample_bytree': 0.29670107750347013, 'subsample': 0.2975142570122117}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:03:30,644]\u001b[0m Trial 128 finished with value: 0.8858917168742909 and parameters: {'n_estimators': 902, 'learning_rate': 0.0831938377359709, 'num_leaves': 230, 'reg_alpha': 0.0009870979083013824, 'reg_lambda': 0.0018519657773943684, 'colsample_bytree': 0.29838521467753726, 'subsample': 0.2959956391897559}. Best is trial 51 with value: 0.8861411044816881.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:05:00,506]\u001b[0m Trial 129 finished with value: 0.8864686876191602 and parameters: {'n_estimators': 902, 'learning_rate': 0.08528113503607251, 'num_leaves': 228, 'reg_alpha': 0.00013368407702789536, 'reg_lambda': 0.0019046455844479086, 'colsample_bytree': 0.29637033880023456, 'subsample': 0.2854706499632219}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:06:31,227]\u001b[0m Trial 130 finished with value: 0.8854888532431948 and parameters: {'n_estimators': 899, 'learning_rate': 0.08342168075499083, 'num_leaves': 228, 'reg_alpha': 0.00012053396058747498, 'reg_lambda': 0.0019603672069004488, 'colsample_bytree': 0.30344496434061285, 'subsample': 0.2903811037411442}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:07:59,414]\u001b[0m Trial 131 finished with value: 0.8862363626476831 and parameters: {'n_estimators': 901, 'learning_rate': 0.08402331294627167, 'num_leaves': 228, 'reg_alpha': 0.0001272262799507694, 'reg_lambda': 0.0019872977906149696, 'colsample_bytree': 0.29332387773665713, 'subsample': 0.2899686294455705}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:09:27,912]\u001b[0m Trial 132 finished with value: 0.8862156538548642 and parameters: {'n_estimators': 897, 'learning_rate': 0.08031338649104924, 'num_leaves': 228, 'reg_alpha': 0.00012764435619118898, 'reg_lambda': 0.002007562532100795, 'colsample_bytree': 0.29545593808089016, 'subsample': 0.2794488495298013}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:10:48,822]\u001b[0m Trial 133 finished with value: 0.8852553400715653 and parameters: {'n_estimators': 900, 'learning_rate': 0.07881712700294301, 'num_leaves': 211, 'reg_alpha': 0.00012677886162965936, 'reg_lambda': 0.0019842983650354353, 'colsample_bytree': 0.28969036694788763, 'subsample': 0.2796553321899451}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:12:09,179]\u001b[0m Trial 134 finished with value: 0.8850546454926003 and parameters: {'n_estimators': 875, 'learning_rate': 0.08289326906499359, 'num_leaves': 222, 'reg_alpha': 0.00010654252889327012, 'reg_lambda': 0.0023546700212619316, 'colsample_bytree': 0.2362296559015034, 'subsample': 0.2928160346496294}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:13:34,827]\u001b[0m Trial 135 finished with value: 0.8853741810880642 and parameters: {'n_estimators': 911, 'learning_rate': 0.08496483842444705, 'num_leaves': 228, 'reg_alpha': 0.00015177217618705016, 'reg_lambda': 0.0038816906822445848, 'colsample_bytree': 0.2644367075907498, 'subsample': 0.2540727237743809}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:14:54,316]\u001b[0m Trial 136 finished with value: 0.8850910418149442 and parameters: {'n_estimators': 888, 'learning_rate': 0.07667148889151043, 'num_leaves': 215, 'reg_alpha': 0.0001409986102160637, 'reg_lambda': 0.003967204313754704, 'colsample_bytree': 0.2577572213778914, 'subsample': 0.2572494244056168}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:16:23,161]\u001b[0m Trial 137 finished with value: 0.8845948612088472 and parameters: {'n_estimators': 907, 'learning_rate': 0.0801818374791246, 'num_leaves': 228, 'reg_alpha': 0.00015719446494359807, 'reg_lambda': 0.004748181886591042, 'colsample_bytree': 0.29613574734489817, 'subsample': 0.27060959601092316}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:17:44,074]\u001b[0m Trial 138 finished with value: 0.882571530677162 and parameters: {'n_estimators': 862, 'learning_rate': 0.08354242662051217, 'num_leaves': 231, 'reg_alpha': 0.00013036476423663228, 'reg_lambda': 0.00619103046618946, 'colsample_bytree': 0.2153709324194979, 'subsample': 0.2525267689747595}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:18:52,365]\u001b[0m Trial 139 finished with value: 0.8833206302679375 and parameters: {'n_estimators': 839, 'learning_rate': 0.08647751951235848, 'num_leaves': 205, 'reg_alpha': 0.00010011617894697408, 'reg_lambda': 0.003371167653090423, 'colsample_bytree': 0.1693654523980146, 'subsample': 0.2952071751160705}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:20:15,449]\u001b[0m Trial 140 finished with value: 0.8854810039081356 and parameters: {'n_estimators': 889, 'learning_rate': 0.07233050247617524, 'num_leaves': 220, 'reg_alpha': 0.0001803189225425011, 'reg_lambda': 0.0019383159582123796, 'colsample_bytree': 0.27197048948621605, 'subsample': 0.2053908931137754}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:21:36,219]\u001b[0m Trial 141 finished with value: 0.8847435648953036 and parameters: {'n_estimators': 893, 'learning_rate': 0.07758082843475467, 'num_leaves': 220, 'reg_alpha': 0.00018272731537005544, 'reg_lambda': 0.0018987301409776345, 'colsample_bytree': 0.26808694102993486, 'subsample': 0.2017675196984623}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:22:57,076]\u001b[0m Trial 142 finished with value: 0.8841209525037644 and parameters: {'n_estimators': 873, 'learning_rate': 0.07303479959632538, 'num_leaves': 225, 'reg_alpha': 0.00016649793395135477, 'reg_lambda': 0.002389275581574354, 'colsample_bytree': 0.23915834130066074, 'subsample': 0.2786277570015079}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:24:21,990]\u001b[0m Trial 143 finished with value: 0.8848134517674225 and parameters: {'n_estimators': 916, 'learning_rate': 0.08442772878897768, 'num_leaves': 212, 'reg_alpha': 0.00012313515349993194, 'reg_lambda': 0.00291456718826775, 'colsample_bytree': 0.3143323441982609, 'subsample': 0.2526989252944125}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:25:50,228]\u001b[0m Trial 144 finished with value: 0.8851418683546788 and parameters: {'n_estimators': 897, 'learning_rate': 0.08064868972291223, 'num_leaves': 231, 'reg_alpha': 0.00010094627305077966, 'reg_lambda': 0.0011029284150260129, 'colsample_bytree': 0.2877721085443359, 'subsample': 0.21620968182295064}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:27:01,694]\u001b[0m Trial 145 finished with value: 0.8840041063696319 and parameters: {'n_estimators': 860, 'learning_rate': 0.06796415441304231, 'num_leaves': 200, 'reg_alpha': 0.00021309189096246014, 'reg_lambda': 0.0018675544928895011, 'colsample_bytree': 0.26784240738001197, 'subsample': 0.3005664818453978}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:28:29,515]\u001b[0m Trial 146 finished with value: 0.8856531074446267 and parameters: {'n_estimators': 936, 'learning_rate': 0.07046450394482955, 'num_leaves': 218, 'reg_alpha': 0.00028727010242982927, 'reg_lambda': 0.003844499168608039, 'colsample_bytree': 0.30978176403205976, 'subsample': 0.15490293736646601}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:29:59,185]\u001b[0m Trial 147 finished with value: 0.885419825652986 and parameters: {'n_estimators': 939, 'learning_rate': 0.06999440531121805, 'num_leaves': 220, 'reg_alpha': 0.00021028085198896137, 'reg_lambda': 0.0015051246962655546, 'colsample_bytree': 0.3219864589753973, 'subsample': 0.15249789706900388}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:31:27,346]\u001b[0m Trial 148 finished with value: 0.8849692161832607 and parameters: {'n_estimators': 881, 'learning_rate': 0.061828293906009885, 'num_leaves': 216, 'reg_alpha': 0.00027564478357199214, 'reg_lambda': 0.007735595582724425, 'colsample_bytree': 0.2897251617244588, 'subsample': 0.12968414613317747}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:32:57,226]\u001b[0m Trial 149 finished with value: 0.8840289661073948 and parameters: {'n_estimators': 925, 'learning_rate': 0.07401887341001546, 'num_leaves': 233, 'reg_alpha': 0.015532032779335146, 'reg_lambda': 0.002269319419236934, 'colsample_bytree': 0.30856657471928883, 'subsample': 0.08864872225627426}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:34:08,873]\u001b[0m Trial 150 finished with value: 0.8837924662355604 and parameters: {'n_estimators': 837, 'learning_rate': 0.07676697785664664, 'num_leaves': 209, 'reg_alpha': 0.0003040302171355178, 'reg_lambda': 0.0012439705565171135, 'colsample_bytree': 0.22239554705762843, 'subsample': 0.16115224913078863}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:35:38,451]\u001b[0m Trial 151 finished with value: 0.8849825099129456 and parameters: {'n_estimators': 933, 'learning_rate': 0.07188140184107962, 'num_leaves': 220, 'reg_alpha': 0.00018305760637934068, 'reg_lambda': 0.0015521934921400157, 'colsample_bytree': 0.3247929751559865, 'subsample': 0.11508042290149723}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:37:09,938]\u001b[0m Trial 152 finished with value: 0.8863222076934225 and parameters: {'n_estimators': 944, 'learning_rate': 0.06536193095013786, 'num_leaves': 227, 'reg_alpha': 0.00022822306256306893, 'reg_lambda': 0.001424791030201611, 'colsample_bytree': 0.30256192481918603, 'subsample': 0.17307955073711517}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:38:39,752]\u001b[0m Trial 153 finished with value: 0.8835063174525157 and parameters: {'n_estimators': 966, 'learning_rate': 0.06217798650112638, 'num_leaves': 227, 'reg_alpha': 0.0001335575729467504, 'reg_lambda': 0.0028693365422406683, 'colsample_bytree': 0.24231556129189724, 'subsample': 0.34831728970466436}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:40:05,222]\u001b[0m Trial 154 finished with value: 0.8852613555501805 and parameters: {'n_estimators': 906, 'learning_rate': 0.06463599261451138, 'num_leaves': 224, 'reg_alpha': 0.00010178390329504334, 'reg_lambda': 0.0020171988069005438, 'colsample_bytree': 0.27971841525382213, 'subsample': 0.1829529443759339}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:41:40,794]\u001b[0m Trial 155 finished with value: 0.8854887014908582 and parameters: {'n_estimators': 948, 'learning_rate': 0.06527635048933936, 'num_leaves': 236, 'reg_alpha': 0.0002638466309432007, 'reg_lambda': 0.005481870124313012, 'colsample_bytree': 0.2984966072131516, 'subsample': 0.1971590917922023}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:43:15,713]\u001b[0m Trial 156 finished with value: 0.8860994725953724 and parameters: {'n_estimators': 949, 'learning_rate': 0.05684752573009422, 'num_leaves': 234, 'reg_alpha': 0.00023572258586410626, 'reg_lambda': 0.004697301101311092, 'colsample_bytree': 0.3070018431123201, 'subsample': 0.1973728373637057}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:44:51,643]\u001b[0m Trial 157 finished with value: 0.8853489725868459 and parameters: {'n_estimators': 952, 'learning_rate': 0.05890586733182557, 'num_leaves': 235, 'reg_alpha': 0.0002328032692699953, 'reg_lambda': 0.005444182899023105, 'colsample_bytree': 0.30246859725749065, 'subsample': 0.1656368503962271}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:45:18,121]\u001b[0m Trial 158 finished with value: 0.8413801203127098 and parameters: {'n_estimators': 946, 'learning_rate': 0.05546416528640279, 'num_leaves': 232, 'reg_alpha': 6.587172729962027, 'reg_lambda': 0.01202199822165847, 'colsample_bytree': 0.343730306845614, 'subsample': 0.14328984814064827}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:46:55,070]\u001b[0m Trial 159 finished with value: 0.8858791638413972 and parameters: {'n_estimators': 960, 'learning_rate': 0.05535442896502764, 'num_leaves': 235, 'reg_alpha': 0.0002753421405543302, 'reg_lambda': 0.003961614534591344, 'colsample_bytree': 0.3174379940806169, 'subsample': 0.1921114854355721}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:48:21,676]\u001b[0m Trial 160 finished with value: 0.8809597607784335 and parameters: {'n_estimators': 968, 'learning_rate': 0.05546665260951806, 'num_leaves': 228, 'reg_alpha': 0.2700534599564338, 'reg_lambda': 0.003824310977007185, 'colsample_bytree': 0.3224311233658279, 'subsample': 0.1148838956560948}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:49:54,343]\u001b[0m Trial 161 finished with value: 0.8850518314835616 and parameters: {'n_estimators': 919, 'learning_rate': 0.05275252493619748, 'num_leaves': 236, 'reg_alpha': 0.0002872427456268979, 'reg_lambda': 0.004953935130637517, 'colsample_bytree': 0.3010694721045702, 'subsample': 0.18943738835162582}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:51:29,859]\u001b[0m Trial 162 finished with value: 0.8850793712883558 and parameters: {'n_estimators': 942, 'learning_rate': 0.06644903403347302, 'num_leaves': 235, 'reg_alpha': 0.00045552643119182285, 'reg_lambda': 0.006589152132904107, 'colsample_bytree': 0.30163136162993426, 'subsample': 0.17077678302378538}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:53:03,183]\u001b[0m Trial 163 finished with value: 0.8842877498579504 and parameters: {'n_estimators': 956, 'learning_rate': 0.059517614349512776, 'num_leaves': 224, 'reg_alpha': 0.00023893015147223535, 'reg_lambda': 0.0033409989962644745, 'colsample_bytree': 0.2505717873888514, 'subsample': 0.22481368946252062}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:55:09,715]\u001b[0m Trial 164 finished with value: 0.8850268143151296 and parameters: {'n_estimators': 968, 'learning_rate': 0.05698133968100672, 'num_leaves': 231, 'reg_alpha': 0.0003404208178146918, 'reg_lambda': 0.008577255397013896, 'colsample_bytree': 0.33621724429837047, 'subsample': 0.13419587765019458}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:56:47,522]\u001b[0m Trial 165 finished with value: 0.8858662743872937 and parameters: {'n_estimators': 921, 'learning_rate': 0.06516140101221589, 'num_leaves': 245, 'reg_alpha': 0.0001290701188381393, 'reg_lambda': 0.0009401047801576647, 'colsample_bytree': 0.3170733371870479, 'subsample': 0.1903582957936203}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:58:14,660]\u001b[0m Trial 166 finished with value: 0.8853301595198714 and parameters: {'n_estimators': 926, 'learning_rate': 0.06119891295714314, 'num_leaves': 215, 'reg_alpha': 0.00012284930124609953, 'reg_lambda': 0.0026172967213665037, 'colsample_bytree': 0.35322138902028205, 'subsample': 0.24118605591518344}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 04:59:58,325]\u001b[0m Trial 167 finished with value: 0.8860996502319116 and parameters: {'n_estimators': 995, 'learning_rate': 0.05272305015248126, 'num_leaves': 244, 'reg_alpha': 0.00016661594139230257, 'reg_lambda': 0.0009877301102881968, 'colsample_bytree': 0.31937800900478686, 'subsample': 0.2160499211487375}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:01:43,062]\u001b[0m Trial 168 finished with value: 0.8856622039348678 and parameters: {'n_estimators': 994, 'learning_rate': 0.05316175215912648, 'num_leaves': 246, 'reg_alpha': 0.0001842142096654535, 'reg_lambda': 0.000989142066960414, 'colsample_bytree': 0.3285690764181506, 'subsample': 0.16226130642736775}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:03:28,599]\u001b[0m Trial 169 finished with value: 0.8855867845519227 and parameters: {'n_estimators': 998, 'learning_rate': 0.05216978290243941, 'num_leaves': 245, 'reg_alpha': 0.00017600555138910727, 'reg_lambda': 0.0009800595440497876, 'colsample_bytree': 0.32346596025997937, 'subsample': 0.15274050129025954}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:05:16,714]\u001b[0m Trial 170 finished with value: 0.8858197314345269 and parameters: {'n_estimators': 998, 'learning_rate': 0.0537158391850976, 'num_leaves': 246, 'reg_alpha': 0.00016039551504410196, 'reg_lambda': 0.0010092042946922277, 'colsample_bytree': 0.3608080601702064, 'subsample': 0.1494579941501338}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:07:02,306]\u001b[0m Trial 171 finished with value: 0.8858944699011791 and parameters: {'n_estimators': 989, 'learning_rate': 0.05253617044681865, 'num_leaves': 247, 'reg_alpha': 0.0001511670060683672, 'reg_lambda': 0.0009601654777467072, 'colsample_bytree': 0.35910001554612914, 'subsample': 0.14905003554105073}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:08:44,269]\u001b[0m Trial 172 finished with value: 0.8834764127024128 and parameters: {'n_estimators': 989, 'learning_rate': 0.05318342312048688, 'num_leaves': 247, 'reg_alpha': 0.07981937580845154, 'reg_lambda': 0.0009238395106773063, 'colsample_bytree': 0.3695286393765592, 'subsample': 0.17523534442638639}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:10:28,535]\u001b[0m Trial 173 finished with value: 0.8858165758987931 and parameters: {'n_estimators': 999, 'learning_rate': 0.05697028367904291, 'num_leaves': 239, 'reg_alpha': 0.00015569791581773583, 'reg_lambda': 0.0006523732240450486, 'colsample_bytree': 0.35361465114453716, 'subsample': 0.08521765905033102}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:12:12,502]\u001b[0m Trial 174 finished with value: 0.8848779930349581 and parameters: {'n_estimators': 995, 'learning_rate': 0.05048981628015603, 'num_leaves': 241, 'reg_alpha': 0.00014970418225465396, 'reg_lambda': 0.0005998123041382304, 'colsample_bytree': 0.3516335649098606, 'subsample': 0.08596143732407566}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:14:01,067]\u001b[0m Trial 175 finished with value: 0.8850181427248971 and parameters: {'n_estimators': 997, 'learning_rate': 0.054256322719378636, 'num_leaves': 249, 'reg_alpha': 0.0001963600130949628, 'reg_lambda': 0.0007398959754789192, 'colsample_bytree': 0.3795756674168552, 'subsample': 0.03826529138568812}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:15:42,629]\u001b[0m Trial 176 finished with value: 0.8851803121571449 and parameters: {'n_estimators': 976, 'learning_rate': 0.05685942549961593, 'num_leaves': 239, 'reg_alpha': 0.0001432762398588257, 'reg_lambda': 0.0005260729673083907, 'colsample_bytree': 0.35653590242398503, 'subsample': 0.07269651866455606}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:17:25,171]\u001b[0m Trial 177 finished with value: 0.8856516798426892 and parameters: {'n_estimators': 976, 'learning_rate': 0.050310778651922745, 'num_leaves': 244, 'reg_alpha': 0.00011889438817860729, 'reg_lambda': 0.0011291284609325429, 'colsample_bytree': 0.34516563403643097, 'subsample': 0.1234724901338552}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:18:16,535]\u001b[0m Trial 178 finished with value: 0.882333548001785 and parameters: {'n_estimators': 481, 'learning_rate': 0.05369865073707392, 'num_leaves': 237, 'reg_alpha': 0.0001023174356162689, 'reg_lambda': 0.0009118700780409095, 'colsample_bytree': 0.37716351478492044, 'subsample': 0.11218457448736313}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:19:59,833]\u001b[0m Trial 179 finished with value: 0.885840100421132 and parameters: {'n_estimators': 962, 'learning_rate': 0.050706103979230546, 'num_leaves': 250, 'reg_alpha': 0.00010153494979506656, 'reg_lambda': 0.0012656311625481819, 'colsample_bytree': 0.3267131290863626, 'subsample': 0.1012483405691384}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:21:43,231]\u001b[0m Trial 180 finished with value: 0.8862028511629599 and parameters: {'n_estimators': 969, 'learning_rate': 0.05725319179634937, 'num_leaves': 250, 'reg_alpha': 0.00010017607824585299, 'reg_lambda': 0.0013407633749920784, 'colsample_bytree': 0.32832813137295663, 'subsample': 0.052536495558384265}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:23:32,091]\u001b[0m Trial 181 finished with value: 0.885487950220498 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0504501255222533, 'num_leaves': 253, 'reg_alpha': 0.00014926898467561517, 'reg_lambda': 0.0013819399196684664, 'colsample_bytree': 0.33743565151287924, 'subsample': 0.01295125372141634}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:25:17,164]\u001b[0m Trial 182 finished with value: 0.8859216618818445 and parameters: {'n_estimators': 966, 'learning_rate': 0.056888385104344484, 'num_leaves': 255, 'reg_alpha': 0.00010093208126968201, 'reg_lambda': 0.0012786714071996604, 'colsample_bytree': 0.31995891551933475, 'subsample': 0.10364725287051535}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:27:25,700]\u001b[0m Trial 183 finished with value: 0.8836070967244769 and parameters: {'n_estimators': 973, 'learning_rate': 0.059244395117970354, 'num_leaves': 255, 'reg_alpha': 0.0001076266583017079, 'reg_lambda': 0.0013557076760425063, 'colsample_bytree': 0.9360488960575517, 'subsample': 0.06213838561888274}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:29:08,270]\u001b[0m Trial 184 finished with value: 0.8859837553457055 and parameters: {'n_estimators': 959, 'learning_rate': 0.054935895952385856, 'num_leaves': 252, 'reg_alpha': 0.00010095891125347733, 'reg_lambda': 0.0007678831988832651, 'colsample_bytree': 0.319909005708699, 'subsample': 0.09982834509402552}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:30:51,637]\u001b[0m Trial 185 finished with value: 0.8857445236423158 and parameters: {'n_estimators': 964, 'learning_rate': 0.05708151587028396, 'num_leaves': 250, 'reg_alpha': 0.00010296066594202009, 'reg_lambda': 0.0007369436592295804, 'colsample_bytree': 0.32138622132447314, 'subsample': 0.04586508534090597}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:32:44,176]\u001b[0m Trial 186 finished with value: 0.8857539493150657 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05715664855764348, 'num_leaves': 251, 'reg_alpha': 0.0001002682066325388, 'reg_lambda': 0.0006688958413076523, 'colsample_bytree': 0.31868251546159426, 'subsample': 0.07105015385175906}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:34:28,013]\u001b[0m Trial 187 finished with value: 0.8856347134990562 and parameters: {'n_estimators': 981, 'learning_rate': 0.05476721218120991, 'num_leaves': 255, 'reg_alpha': 0.00010191486162297394, 'reg_lambda': 0.0006408996584850114, 'colsample_bytree': 0.28365109879116673, 'subsample': 0.029857323324552737}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:36:16,608]\u001b[0m Trial 188 finished with value: 0.8859825629793943 and parameters: {'n_estimators': 994, 'learning_rate': 0.057198626904598045, 'num_leaves': 250, 'reg_alpha': 0.0001299175777854307, 'reg_lambda': 0.0008289167871915914, 'colsample_bytree': 0.360376356542532, 'subsample': 0.09476790716157538}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:38:03,484]\u001b[0m Trial 189 finished with value: 0.8857792673882029 and parameters: {'n_estimators': 961, 'learning_rate': 0.06082043372954797, 'num_leaves': 255, 'reg_alpha': 0.00013380416682626708, 'reg_lambda': 0.0011094158576036804, 'colsample_bytree': 0.36230217544025306, 'subsample': 0.10013318642455236}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:39:46,714]\u001b[0m Trial 190 finished with value: 0.8861740284801124 and parameters: {'n_estimators': 959, 'learning_rate': 0.06050019046363718, 'num_leaves': 246, 'reg_alpha': 0.00013096157731608797, 'reg_lambda': 0.0012261891631768398, 'colsample_bytree': 0.3567134403169006, 'subsample': 0.1017538316323162}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:41:29,715]\u001b[0m Trial 191 finished with value: 0.8859679935563392 and parameters: {'n_estimators': 959, 'learning_rate': 0.06319703686151038, 'num_leaves': 246, 'reg_alpha': 0.0001364056505518253, 'reg_lambda': 0.001241457369798296, 'colsample_bytree': 0.3605118906491357, 'subsample': 0.1026473679729313}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:43:13,478]\u001b[0m Trial 192 finished with value: 0.8854746553431788 and parameters: {'n_estimators': 981, 'learning_rate': 0.06346327035412593, 'num_leaves': 244, 'reg_alpha': 0.00015168729782236094, 'reg_lambda': 0.0008366343985679097, 'colsample_bytree': 0.33841686502423723, 'subsample': 0.09941496670523789}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:44:55,631]\u001b[0m Trial 193 finished with value: 0.8861629341391168 and parameters: {'n_estimators': 952, 'learning_rate': 0.05769805473473472, 'num_leaves': 247, 'reg_alpha': 0.000126006245687174, 'reg_lambda': 0.001313548632257886, 'colsample_bytree': 0.35846859546750215, 'subsample': 0.07842834264488367}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:46:35,895]\u001b[0m Trial 194 finished with value: 0.8862393947590197 and parameters: {'n_estimators': 945, 'learning_rate': 0.060115169929578056, 'num_leaves': 248, 'reg_alpha': 0.00012614850669327965, 'reg_lambda': 0.0013489301043128777, 'colsample_bytree': 0.32253704477032485, 'subsample': 0.11158775656983583}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:48:16,940]\u001b[0m Trial 195 finished with value: 0.8855639573481865 and parameters: {'n_estimators': 947, 'learning_rate': 0.05940173231883217, 'num_leaves': 249, 'reg_alpha': 0.00012345749623936722, 'reg_lambda': 0.0014880394435223489, 'colsample_bytree': 0.31405131779989276, 'subsample': 0.0655328948042127}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:49:56,860]\u001b[0m Trial 196 finished with value: 0.8855111738381316 and parameters: {'n_estimators': 922, 'learning_rate': 0.0610331613137963, 'num_leaves': 255, 'reg_alpha': 0.00010235961609725901, 'reg_lambda': 0.0013006038994038114, 'colsample_bytree': 0.295022966908185, 'subsample': 0.10396906005815074}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:51:36,682]\u001b[0m Trial 197 finished with value: 0.8851599812908931 and parameters: {'n_estimators': 955, 'learning_rate': 0.06358273326144193, 'num_leaves': 250, 'reg_alpha': 0.00012421205886798618, 'reg_lambda': 0.0012569343631371652, 'colsample_bytree': 0.27807774826562104, 'subsample': 0.05156720460993389}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:53:15,007]\u001b[0m Trial 198 finished with value: 0.8848514390572089 and parameters: {'n_estimators': 938, 'learning_rate': 0.05183252256683982, 'num_leaves': 244, 'reg_alpha': 0.00018600046828567816, 'reg_lambda': 0.0016128449785488008, 'colsample_bytree': 0.3314832386150611, 'subsample': 0.12584224302449504}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:54:56,618]\u001b[0m Trial 199 finished with value: 0.884026043984593 and parameters: {'n_estimators': 966, 'learning_rate': 0.05794417159114608, 'num_leaves': 255, 'reg_alpha': 0.0346588377210163, 'reg_lambda': 0.0012557711660211265, 'colsample_bytree': 0.3172530167578738, 'subsample': 0.08770561081659145}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:56:31,315]\u001b[0m Trial 200 finished with value: 0.8858325567278429 and parameters: {'n_estimators': 920, 'learning_rate': 0.055216713207405246, 'num_leaves': 244, 'reg_alpha': 0.00010100674577531734, 'reg_lambda': 0.000874659168014186, 'colsample_bytree': 0.28714256398053806, 'subsample': 0.10623377812854094}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:58:04,861]\u001b[0m Trial 201 finished with value: 0.8858374396225855 and parameters: {'n_estimators': 919, 'learning_rate': 0.055487523108588316, 'num_leaves': 242, 'reg_alpha': 0.00010199028099591785, 'reg_lambda': 0.0009075747665509328, 'colsample_bytree': 0.29151426780131073, 'subsample': 0.08012543004879533}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 05:59:41,722]\u001b[0m Trial 202 finished with value: 0.885570437463491 and parameters: {'n_estimators': 945, 'learning_rate': 0.06005680272905196, 'num_leaves': 241, 'reg_alpha': 0.00014265212329921917, 'reg_lambda': 0.0015877053820430023, 'colsample_bytree': 0.31053631966539436, 'subsample': 0.026848052895961923}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:01:20,557]\u001b[0m Trial 203 finished with value: 0.8857521238931522 and parameters: {'n_estimators': 915, 'learning_rate': 0.05652236256168844, 'num_leaves': 250, 'reg_alpha': 0.00020903534008393665, 'reg_lambda': 0.0010693477773903325, 'colsample_bytree': 0.3310575159252357, 'subsample': 0.07677648478459258}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:02:59,717]\u001b[0m Trial 204 finished with value: 0.8855102433168456 and parameters: {'n_estimators': 961, 'learning_rate': 0.05801817923914561, 'num_leaves': 255, 'reg_alpha': 0.00010139006515426064, 'reg_lambda': 0.0008499264354551541, 'colsample_bytree': 0.2562962407954583, 'subsample': 0.1285029622304179}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:04:32,885]\u001b[0m Trial 205 finished with value: 0.8848416896198973 and parameters: {'n_estimators': 933, 'learning_rate': 0.051704953148058015, 'num_leaves': 239, 'reg_alpha': 0.00013067755401050015, 'reg_lambda': 0.0012748883596688688, 'colsample_bytree': 0.2835752525837821, 'subsample': 0.05562208130676559}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:06:15,968]\u001b[0m Trial 206 finished with value: 0.8858022398867293 and parameters: {'n_estimators': 976, 'learning_rate': 0.05513829535395301, 'num_leaves': 247, 'reg_alpha': 0.00010120279597599502, 'reg_lambda': 0.0014999844230776968, 'colsample_bytree': 0.30644751210409604, 'subsample': 0.10176763848129328}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:07:53,773]\u001b[0m Trial 207 finished with value: 0.8856857741287232 and parameters: {'n_estimators': 945, 'learning_rate': 0.06201771166762201, 'num_leaves': 235, 'reg_alpha': 0.00019189491506241954, 'reg_lambda': 0.0010946092298699849, 'colsample_bytree': 0.34236834044158737, 'subsample': 0.0772959375924705}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:09:30,684]\u001b[0m Trial 208 finished with value: 0.8852760067341029 and parameters: {'n_estimators': 906, 'learning_rate': 0.06388755357871607, 'num_leaves': 242, 'reg_alpha': 0.00013029305465168028, 'reg_lambda': 0.0017148715676910716, 'colsample_bytree': 0.3786410325673814, 'subsample': 0.1380178297576951}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:11:07,580]\u001b[0m Trial 209 finished with value: 0.8853757841913847 and parameters: {'n_estimators': 928, 'learning_rate': 0.0664940244253321, 'num_leaves': 250, 'reg_alpha': 0.00022325061873999978, 'reg_lambda': 0.0008172377144229186, 'colsample_bytree': 0.27030338055125563, 'subsample': 0.12169218733257336}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:12:49,887]\u001b[0m Trial 210 finished with value: 0.8860194119587803 and parameters: {'n_estimators': 959, 'learning_rate': 0.05878809037198651, 'num_leaves': 255, 'reg_alpha': 0.00016926937283385878, 'reg_lambda': 0.001102273839203895, 'colsample_bytree': 0.29746353167274314, 'subsample': 0.05374231113165733}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:14:32,456]\u001b[0m Trial 211 finished with value: 0.8857435535945977 and parameters: {'n_estimators': 951, 'learning_rate': 0.05883451952947672, 'num_leaves': 252, 'reg_alpha': 0.00016091137351088248, 'reg_lambda': 0.0011223168872204715, 'colsample_bytree': 0.3191253465893614, 'subsample': 0.06750145122516381}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:16:17,488]\u001b[0m Trial 212 finished with value: 0.885588625078103 and parameters: {'n_estimators': 983, 'learning_rate': 0.05000220747258689, 'num_leaves': 246, 'reg_alpha': 0.00010040357238609533, 'reg_lambda': 0.17794584494487853, 'colsample_bytree': 0.296917002762563, 'subsample': 0.03948517296443377}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:17:57,894]\u001b[0m Trial 213 finished with value: 0.8863483243768405 and parameters: {'n_estimators': 958, 'learning_rate': 0.055407314195969726, 'num_leaves': 241, 'reg_alpha': 0.00016861758499645146, 'reg_lambda': 0.0014795963402638248, 'colsample_bytree': 0.3341036435936747, 'subsample': 0.09318994779154197}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:19:43,614]\u001b[0m Trial 214 finished with value: 0.8858333662742911 and parameters: {'n_estimators': 967, 'learning_rate': 0.053682603560596655, 'num_leaves': 252, 'reg_alpha': 0.00018815493102937353, 'reg_lambda': 0.0017775079346300522, 'colsample_bytree': 0.34183942442296444, 'subsample': 0.002777691376408105}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:21:25,758]\u001b[0m Trial 215 finished with value: 0.8860725584493079 and parameters: {'n_estimators': 982, 'learning_rate': 0.05944843948296155, 'num_leaves': 237, 'reg_alpha': 0.0001590719460180214, 'reg_lambda': 0.001399647080726236, 'colsample_bytree': 0.3532716730957519, 'subsample': 0.10700032800547485}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:23:06,015]\u001b[0m Trial 216 finished with value: 0.8860785688243779 and parameters: {'n_estimators': 983, 'learning_rate': 0.06060253137311912, 'num_leaves': 233, 'reg_alpha': 0.00021835869824131108, 'reg_lambda': 0.0015831859909020694, 'colsample_bytree': 0.3626898981509654, 'subsample': 0.05340005637901909}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:24:48,907]\u001b[0m Trial 217 finished with value: 0.8860510432366008 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0605560448075472, 'num_leaves': 233, 'reg_alpha': 0.00022620714271553874, 'reg_lambda': 0.002319611708237919, 'colsample_bytree': 0.3643149589754119, 'subsample': 0.09324619837146247}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:26:29,799]\u001b[0m Trial 218 finished with value: 0.8854336119866424 and parameters: {'n_estimators': 999, 'learning_rate': 0.06037160870050405, 'num_leaves': 230, 'reg_alpha': 0.00022349719168986715, 'reg_lambda': 0.002190805135306584, 'colsample_bytree': 0.3680707503892968, 'subsample': 0.05517814559413461}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:28:12,603]\u001b[0m Trial 219 finished with value: 0.8853981178036271 and parameters: {'n_estimators': 985, 'learning_rate': 0.0584943948673719, 'num_leaves': 233, 'reg_alpha': 0.00016704407871677294, 'reg_lambda': 0.001619966671188795, 'colsample_bytree': 0.4011062851706021, 'subsample': 0.09559301106346185}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:29:55,894]\u001b[0m Trial 220 finished with value: 0.8849522980609761 and parameters: {'n_estimators': 984, 'learning_rate': 0.06089202039653358, 'num_leaves': 238, 'reg_alpha': 0.000219106709031679, 'reg_lambda': 0.0013995886174967714, 'colsample_bytree': 0.3886170956947433, 'subsample': 0.11455911359421345}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:31:41,317]\u001b[0m Trial 221 finished with value: 0.8852420898782407 and parameters: {'n_estimators': 968, 'learning_rate': 0.05648651166948045, 'num_leaves': 233, 'reg_alpha': 0.00016445726295242038, 'reg_lambda': 0.0021142072058935577, 'colsample_bytree': 0.36385431459999923, 'subsample': 0.030613350027024363}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:33:18,150]\u001b[0m Trial 222 finished with value: 0.8855408121083574 and parameters: {'n_estimators': 982, 'learning_rate': 0.06281109903941882, 'num_leaves': 226, 'reg_alpha': 0.00024173102714434455, 'reg_lambda': 0.0017332828251322933, 'colsample_bytree': 0.3469869079844025, 'subsample': 0.07977364511810575}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:35:00,559]\u001b[0m Trial 223 finished with value: 0.88532953250714 and parameters: {'n_estimators': 999, 'learning_rate': 0.05816696899828522, 'num_leaves': 236, 'reg_alpha': 0.00017922802959318635, 'reg_lambda': 0.0022294222537624555, 'colsample_bytree': 0.34383789428008865, 'subsample': 0.06144115843028018}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:36:39,878]\u001b[0m Trial 224 finished with value: 0.8850907298699179 and parameters: {'n_estimators': 946, 'learning_rate': 0.059992903999945967, 'num_leaves': 238, 'reg_alpha': 0.00013618026659058827, 'reg_lambda': 0.0013560670455794591, 'colsample_bytree': 0.3615123149998476, 'subsample': 0.1373189419972106}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:36:53,608]\u001b[0m Trial 225 finished with value: 0.8633543629449676 and parameters: {'n_estimators': 115, 'learning_rate': 0.05476296413366919, 'num_leaves': 228, 'reg_alpha': 0.0002590629310104523, 'reg_lambda': 0.0017121916816695696, 'colsample_bytree': 0.38974884700190393, 'subsample': 0.0951027608369411}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:38:29,677]\u001b[0m Trial 226 finished with value: 0.8844409485678181 and parameters: {'n_estimators': 958, 'learning_rate': 0.05724885232848638, 'num_leaves': 232, 'reg_alpha': 0.00019800155304192714, 'reg_lambda': 0.001108508689489923, 'colsample_bytree': 0.3308902466953825, 'subsample': 0.12029320614640451}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:40:09,929]\u001b[0m Trial 227 finished with value: 0.8853433657621608 and parameters: {'n_estimators': 972, 'learning_rate': 0.06265483556205158, 'num_leaves': 241, 'reg_alpha': 0.00014861069883556245, 'reg_lambda': 0.0027752690792056008, 'colsample_bytree': 0.30969972242288163, 'subsample': 0.0541278187228398}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:41:46,700]\u001b[0m Trial 228 finished with value: 0.8858173591964995 and parameters: {'n_estimators': 941, 'learning_rate': 0.052820016935623736, 'num_leaves': 237, 'reg_alpha': 0.00012514719519622226, 'reg_lambda': 0.0015861743426381792, 'colsample_bytree': 0.3614173891377842, 'subsample': 0.09268294085981996}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:43:34,590]\u001b[0m Trial 229 finished with value: 0.885630811119506 and parameters: {'n_estimators': 986, 'learning_rate': 0.058330820678187865, 'num_leaves': 255, 'reg_alpha': 0.00021543002464951175, 'reg_lambda': 0.0023583179617548554, 'colsample_bytree': 0.37474778853020935, 'subsample': 0.022145973566336102}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:45:17,100]\u001b[0m Trial 230 finished with value: 0.8850710682527738 and parameters: {'n_estimators': 998, 'learning_rate': 0.055177155669553044, 'num_leaves': 246, 'reg_alpha': 0.00016326482931367154, 'reg_lambda': 0.001297444098604694, 'colsample_bytree': 0.2721773888113822, 'subsample': 0.11456550420971445}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:46:56,465]\u001b[0m Trial 231 finished with value: 0.885499551170293 and parameters: {'n_estimators': 936, 'learning_rate': 0.06533995305933239, 'num_leaves': 244, 'reg_alpha': 0.0001282609928838775, 'reg_lambda': 0.0009586153013201455, 'colsample_bytree': 0.3219781469403671, 'subsample': 0.17064966219149963}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:48:37,066]\u001b[0m Trial 232 finished with value: 0.8863236072258648 and parameters: {'n_estimators': 960, 'learning_rate': 0.06833029708926414, 'num_leaves': 244, 'reg_alpha': 0.00012991816346926032, 'reg_lambda': 0.0007853760498524559, 'colsample_bytree': 0.3029699298425636, 'subsample': 0.20173975308368108}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:50:12,037]\u001b[0m Trial 233 finished with value: 0.8852313339373804 and parameters: {'n_estimators': 964, 'learning_rate': 0.06711329690201516, 'num_leaves': 230, 'reg_alpha': 0.00016647952790322371, 'reg_lambda': 0.0005139270248711557, 'colsample_bytree': 0.29847078212823985, 'subsample': 0.20905978739925624}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:51:15,884]\u001b[0m Trial 234 finished with value: 0.8827824088650914 and parameters: {'n_estimators': 955, 'learning_rate': 0.06103957862719244, 'num_leaves': 147, 'reg_alpha': 0.0002868539033149848, 'reg_lambda': 0.0007767774547842658, 'colsample_bytree': 0.34101124583889303, 'subsample': 0.13981962729505124}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:52:55,115]\u001b[0m Trial 235 finished with value: 0.8860079388579856 and parameters: {'n_estimators': 979, 'learning_rate': 0.05645043119820257, 'num_leaves': 240, 'reg_alpha': 0.00012384305573856272, 'reg_lambda': 0.0011169168182332213, 'colsample_bytree': 0.3087027246801997, 'subsample': 0.08049802504352953}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:54:36,094]\u001b[0m Trial 236 finished with value: 0.8856760037043866 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05901677725927426, 'num_leaves': 241, 'reg_alpha': 0.00012249139809910245, 'reg_lambda': 0.0011247993815562988, 'colsample_bytree': 0.2850874275910113, 'subsample': 0.07491133719905535}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:56:15,499]\u001b[0m Trial 237 finished with value: 0.8848599384269085 and parameters: {'n_estimators': 980, 'learning_rate': 0.061627083015315894, 'num_leaves': 248, 'reg_alpha': 0.00012538350865788032, 'reg_lambda': 0.0007131181945727502, 'colsample_bytree': 0.25156663846501043, 'subsample': 0.0465548511709858}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:58:04,130]\u001b[0m Trial 238 finished with value: 0.8854404933570631 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06866497855538067, 'num_leaves': 255, 'reg_alpha': 0.00010047581440649038, 'reg_lambda': 0.0013929190002840044, 'colsample_bytree': 0.30110791584679114, 'subsample': 0.08344732221871833}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 06:58:42,944]\u001b[0m Trial 239 finished with value: 0.8666967476145608 and parameters: {'n_estimators': 980, 'learning_rate': 0.06356176798795053, 'num_leaves': 65, 'reg_alpha': 1.5937890757574704, 'reg_lambda': 0.001065759759333698, 'colsample_bytree': 0.3459143703836499, 'subsample': 0.10884938913420732}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:00:21,411]\u001b[0m Trial 240 finished with value: 0.885486550740133 and parameters: {'n_estimators': 950, 'learning_rate': 0.057677457001637636, 'num_leaves': 242, 'reg_alpha': 0.00015364284912797592, 'reg_lambda': 0.0018092540092824107, 'colsample_bytree': 0.3281612601564878, 'subsample': 0.0713017258648535}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:01:58,283]\u001b[0m Trial 241 finished with value: 0.8852237751938425 and parameters: {'n_estimators': 964, 'learning_rate': 0.056625741374612765, 'num_leaves': 236, 'reg_alpha': 0.00019389827247042892, 'reg_lambda': 0.0013868709050178928, 'colsample_bytree': 0.30995587757032556, 'subsample': 0.09567361848861235}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:03:33,206]\u001b[0m Trial 242 finished with value: 0.8856761067647415 and parameters: {'n_estimators': 967, 'learning_rate': 0.05537829842434178, 'num_leaves': 233, 'reg_alpha': 0.0001483560981864602, 'reg_lambda': 0.0018890673794954953, 'colsample_bytree': 0.28680098315911223, 'subsample': 0.2173594529518908}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:05:04,579]\u001b[0m Trial 243 finished with value: 0.8854524436431601 and parameters: {'n_estimators': 935, 'learning_rate': 0.05384509272805053, 'num_leaves': 226, 'reg_alpha': 0.0002366781574882115, 'reg_lambda': 0.0008693089521591281, 'colsample_bytree': 0.31729593274830736, 'subsample': 0.1544748388022979}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:06:48,317]\u001b[0m Trial 244 finished with value: 0.8853292939926043 and parameters: {'n_estimators': 952, 'learning_rate': 0.05966667304013606, 'num_leaves': 248, 'reg_alpha': 0.00012160386333043845, 'reg_lambda': 0.001117001517656932, 'colsample_bytree': 0.35351387459081246, 'subsample': 0.19013800433375352}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:08:29,325]\u001b[0m Trial 245 finished with value: 0.8852871354979859 and parameters: {'n_estimators': 982, 'learning_rate': 0.05643391728421173, 'num_leaves': 238, 'reg_alpha': 0.00018736941391061845, 'reg_lambda': 0.0014428171137801974, 'colsample_bytree': 0.3308078034673967, 'subsample': 0.12217590369762446}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:10:12,779]\u001b[0m Trial 246 finished with value: 0.8852105561946324 and parameters: {'n_estimators': 999, 'learning_rate': 0.052050039991969166, 'num_leaves': 245, 'reg_alpha': 0.0001502056873252089, 'reg_lambda': 0.0005966523902553, 'colsample_bytree': 0.27170471637976484, 'subsample': 0.04983724435695883}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:11:47,329]\u001b[0m Trial 247 finished with value: 0.8855090190774784 and parameters: {'n_estimators': 934, 'learning_rate': 0.05998419486632582, 'num_leaves': 233, 'reg_alpha': 0.0002257484952199981, 'reg_lambda': 0.0020971110791495867, 'colsample_bytree': 0.30436522668090127, 'subsample': 0.08427191125436574}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:13:35,138]\u001b[0m Trial 248 finished with value: 0.886072618756398 and parameters: {'n_estimators': 968, 'learning_rate': 0.06260977367798944, 'num_leaves': 255, 'reg_alpha': 0.00010051054523265418, 'reg_lambda': 0.0011797591375994334, 'colsample_bytree': 0.3734408648960799, 'subsample': 0.1045590773706854}. Best is trial 129 with value: 0.8864686876191602.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:15:23,925]\u001b[0m Trial 249 finished with value: 0.8866133965955111 and parameters: {'n_estimators': 973, 'learning_rate': 0.06404097408570102, 'num_leaves': 255, 'reg_alpha': 0.00011715857558509575, 'reg_lambda': 0.0008249293328772093, 'colsample_bytree': 0.3805039894547897, 'subsample': 0.10828521649376942}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:17:13,193]\u001b[0m Trial 250 finished with value: 0.8860258519728645 and parameters: {'n_estimators': 974, 'learning_rate': 0.06535649985317396, 'num_leaves': 250, 'reg_alpha': 0.00010354096492748979, 'reg_lambda': 0.0008206702542418754, 'colsample_bytree': 0.4168179407460993, 'subsample': 0.10605512252980753}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:19:03,532]\u001b[0m Trial 251 finished with value: 0.8856314584962796 and parameters: {'n_estimators': 972, 'learning_rate': 0.06512822223809822, 'num_leaves': 254, 'reg_alpha': 0.00010463207623540767, 'reg_lambda': 0.0007619371812188183, 'colsample_bytree': 0.4227823070793704, 'subsample': 0.10475182460610627}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:20:50,039]\u001b[0m Trial 252 finished with value: 0.8855327110813442 and parameters: {'n_estimators': 953, 'learning_rate': 0.06349599188171667, 'num_leaves': 255, 'reg_alpha': 0.000103517361920987, 'reg_lambda': 0.0005305263997470656, 'colsample_bytree': 0.39040104317283475, 'subsample': 0.06078930979715893}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:22:40,372]\u001b[0m Trial 253 finished with value: 0.8860737890941444 and parameters: {'n_estimators': 973, 'learning_rate': 0.06665409589916536, 'num_leaves': 251, 'reg_alpha': 0.00010141156493079702, 'reg_lambda': 0.0007189101888176614, 'colsample_bytree': 0.41117133526065336, 'subsample': 0.09182704090223806}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:24:33,268]\u001b[0m Trial 254 finished with value: 0.8855600902266966 and parameters: {'n_estimators': 999, 'learning_rate': 0.0681359626828247, 'num_leaves': 251, 'reg_alpha': 0.0001227545139225996, 'reg_lambda': 0.0007502344142056362, 'colsample_bytree': 0.41508310639110785, 'subsample': 0.0833940507043777}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:26:24,705]\u001b[0m Trial 255 finished with value: 0.8858264675082165 and parameters: {'n_estimators': 979, 'learning_rate': 0.06789973206908943, 'num_leaves': 250, 'reg_alpha': 0.00010041438204333375, 'reg_lambda': 0.000627588660048068, 'colsample_bytree': 0.4316571365889956, 'subsample': 0.0013219185628284141}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:28:05,479]\u001b[0m Trial 256 finished with value: 0.8852540288134957 and parameters: {'n_estimators': 946, 'learning_rate': 0.06579254556538841, 'num_leaves': 244, 'reg_alpha': 0.0001340522313618327, 'reg_lambda': 0.0009143625175628121, 'colsample_bytree': 0.3738622849724491, 'subsample': 0.041298892180798547}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:29:53,602]\u001b[0m Trial 257 finished with value: 0.8860916942412447 and parameters: {'n_estimators': 975, 'learning_rate': 0.06267469353489229, 'num_leaves': 250, 'reg_alpha': 0.00010054952233538191, 'reg_lambda': 0.0004410881357855703, 'colsample_bytree': 0.4067787646946182, 'subsample': 0.07029920836758899}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:31:49,943]\u001b[0m Trial 258 finished with value: 0.8857501898367053 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06256935306775677, 'num_leaves': 251, 'reg_alpha': 0.0001001408812040249, 'reg_lambda': 0.0004490557271796664, 'colsample_bytree': 0.3848736299239795, 'subsample': 0.06813466824426347}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:33:43,643]\u001b[0m Trial 259 finished with value: 0.8860324554045306 and parameters: {'n_estimators': 984, 'learning_rate': 0.06135268334730943, 'num_leaves': 254, 'reg_alpha': 0.00017427791481982056, 'reg_lambda': 0.0005394309064714153, 'colsample_bytree': 0.4069827080857422, 'subsample': 0.06970848375806259}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:35:37,057]\u001b[0m Trial 260 finished with value: 0.8858097718626965 and parameters: {'n_estimators': 974, 'learning_rate': 0.06562090496218845, 'num_leaves': 254, 'reg_alpha': 0.00017861090709869948, 'reg_lambda': 0.00040455514250865507, 'colsample_bytree': 0.4577382230434143, 'subsample': 0.03748833723585278}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:37:19,492]\u001b[0m Trial 261 finished with value: 0.8859631093596722 and parameters: {'n_estimators': 934, 'learning_rate': 0.061856631118114624, 'num_leaves': 242, 'reg_alpha': 0.0001716131421561794, 'reg_lambda': 0.0004268141194247612, 'colsample_bytree': 0.4438740056640702, 'subsample': 0.06405433928231076}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:39:12,271]\u001b[0m Trial 262 finished with value: 0.8859944069242861 and parameters: {'n_estimators': 980, 'learning_rate': 0.07055471474970869, 'num_leaves': 254, 'reg_alpha': 0.00010254113011456606, 'reg_lambda': 0.0005628891678989439, 'colsample_bytree': 0.41007509368137846, 'subsample': 0.01337703253413891}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:41:01,702]\u001b[0m Trial 263 finished with value: 0.8858916351635594 and parameters: {'n_estimators': 984, 'learning_rate': 0.06776704249439794, 'num_leaves': 248, 'reg_alpha': 0.00012393582742103968, 'reg_lambda': 0.0010717010912073266, 'colsample_bytree': 0.40455977983675273, 'subsample': 0.02541837586391163}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:42:54,233]\u001b[0m Trial 264 finished with value: 0.8855158252487314 and parameters: {'n_estimators': 979, 'learning_rate': 0.07016711177742085, 'num_leaves': 255, 'reg_alpha': 0.0001009022839232505, 'reg_lambda': 0.0005659116515457811, 'colsample_bytree': 0.4135137843065997, 'subsample': 0.022907411945130445}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:43:40,770]\u001b[0m Trial 265 finished with value: 0.883386853431273 and parameters: {'n_estimators': 418, 'learning_rate': 0.06577296172789486, 'num_leaves': 240, 'reg_alpha': 0.00017444755525993023, 'reg_lambda': 0.0004981669502591833, 'colsample_bytree': 0.4311446867479606, 'subsample': 0.05749159285647888}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:45:41,331]\u001b[0m Trial 266 finished with value: 0.8860901379030575 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06346987257854987, 'num_leaves': 245, 'reg_alpha': 0.00022083378497300265, 'reg_lambda': 0.000612498530310337, 'colsample_bytree': 0.41247427637918754, 'subsample': 0.0786168036284303}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:47:23,213]\u001b[0m Trial 267 finished with value: 0.8851184076806653 and parameters: {'n_estimators': 921, 'learning_rate': 0.06390948308203412, 'num_leaves': 240, 'reg_alpha': 0.00021732999627837189, 'reg_lambda': 0.000622852987679522, 'colsample_bytree': 0.3902284651718693, 'subsample': 0.08031189019120373}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:49:19,078]\u001b[0m Trial 268 finished with value: 0.8863994694753787 and parameters: {'n_estimators': 999, 'learning_rate': 0.06107986553872763, 'num_leaves': 246, 'reg_alpha': 0.000262462253288106, 'reg_lambda': 0.0003696498719119339, 'colsample_bytree': 0.4028613829778908, 'subsample': 0.12770145248065679}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:51:19,683]\u001b[0m Trial 269 finished with value: 0.8853385137490708 and parameters: {'n_estimators': 997, 'learning_rate': 0.06223247112891261, 'num_leaves': 246, 'reg_alpha': 0.00028482927069033127, 'reg_lambda': 0.00034045363038129767, 'colsample_bytree': 0.4725873407500391, 'subsample': 0.12404524427795671}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:53:11,215]\u001b[0m Trial 270 finished with value: 0.8855801858071854 and parameters: {'n_estimators': 950, 'learning_rate': 0.06060313023561693, 'num_leaves': 248, 'reg_alpha': 0.00030849242550614437, 'reg_lambda': 0.00032194251442079505, 'colsample_bytree': 0.4003423542485744, 'subsample': 0.13186562287536568}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:55:02,736]\u001b[0m Trial 271 finished with value: 0.8861280401511257 and parameters: {'n_estimators': 962, 'learning_rate': 0.06434716103974968, 'num_leaves': 245, 'reg_alpha': 0.00022394350583550388, 'reg_lambda': 0.0006986207078133417, 'colsample_bytree': 0.41915254565328913, 'subsample': 0.12572474150605292}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:56:56,737]\u001b[0m Trial 272 finished with value: 0.8856752280079796 and parameters: {'n_estimators': 995, 'learning_rate': 0.06470993357296727, 'num_leaves': 243, 'reg_alpha': 0.00035916325727944803, 'reg_lambda': 0.00036125126334783983, 'colsample_bytree': 0.44265605700956534, 'subsample': 0.12277954201626368}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 07:59:13,579]\u001b[0m Trial 273 finished with value: 0.8855465678230857 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06399455117173797, 'num_leaves': 223, 'reg_alpha': 0.000244687888904171, 'reg_lambda': 0.0005312058307449968, 'colsample_bytree': 0.42622612942515964, 'subsample': 0.14610064782181048}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 08:01:50,911]\u001b[0m Trial 274 finished with value: 0.8853298846555996 and parameters: {'n_estimators': 967, 'learning_rate': 0.06628751428642102, 'num_leaves': 236, 'reg_alpha': 0.00021823865858253187, 'reg_lambda': 0.0004600845126832769, 'colsample_bytree': 0.40614369690220153, 'subsample': 0.11933437103089228}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 08:04:17,199]\u001b[0m Trial 275 finished with value: 0.8850481082507834 and parameters: {'n_estimators': 913, 'learning_rate': 0.061449882808306155, 'num_leaves': 244, 'reg_alpha': 0.00025358054322484254, 'reg_lambda': 0.0006923358214287843, 'colsample_bytree': 0.4473249323992657, 'subsample': 0.1088291958710573}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 08:06:37,818]\u001b[0m Trial 276 finished with value: 0.8855211522078132 and parameters: {'n_estimators': 941, 'learning_rate': 0.06832272698821505, 'num_leaves': 248, 'reg_alpha': 0.000382650134498273, 'reg_lambda': 0.0003970432416153446, 'colsample_bytree': 0.3878767492581952, 'subsample': 0.1373363287727013}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n",
      "\u001b[32m[I 2023-01-11 08:09:01,099]\u001b[0m Trial 277 finished with value: 0.8852628571014376 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06187165971424923, 'num_leaves': 229, 'reg_alpha': 0.0001874065027731886, 'reg_lambda': 0.0006684463427708616, 'colsample_bytree': 0.4242061784083551, 'subsample': 0.17163478196899826}. Best is trial 249 with value: 0.8866133965955111.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lgb_params = tune_model('lgb', X, y, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = tune_model('rf', X, y, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_parm= tune_model('ets', X, y, n_trials=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7d8059f8b686b32e6b3f4fd5359349a623b5020926c204d6b9343af24b904c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
